{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "###################\n",
    "import pyvista as pv\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "\n",
    "import cmocean\n",
    "\n",
    "import glob\n",
    "\n",
    "import os\n",
    "\n",
    "import itertools\n",
    "\n",
    "import trame\n",
    "\n",
    "import ipywidgets\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import chirp, find_peaks, peak_widths\n",
    "\n",
    "from numpy import loadtxt\n",
    "\n",
    "pv.set_jupyter_backend('ipyvtklink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load participant IDs ###\n",
    "lines = loadtxt(\"dummy_data/one_hander/all_IDs.txt\", dtype=str, comments=\"#\", delimiter=\" \", unpack=False)\n",
    "print(lines)\n",
    "subjects = lines\n",
    "\n",
    "### specifiy folder structure of MIPAV results (need to match order of participant IDs) ###\n",
    "subject_folder = ['00','01']\n",
    "#print(subject_folder)\n",
    "\n",
    "#### define the colors we want to use to visualise the different fingers ###\n",
    "red = np.array([1, 0, 0, 1])\n",
    "magenta = np.array([1, 0, 1, 1])\n",
    "blue = np.array([0, 0, 1, 1])\n",
    "green = np.array([0, 1, 0, 1])\n",
    "yellow = np.array([255/256, 247/256, 0/256, 1])\n",
    "grey = np.array([0.75, 0.75, 0.75, 1])\n",
    "white = np.array([1, 1, 1, 1])\n",
    "black = np.array([0, 0, 0, 1])\n",
    "olive = np.array([232/256, 241/256, 177/256, 1])\n",
    "\n",
    "folder = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change ID and folder for subject to analyze here: #\n",
    "subj = 0\n",
    "\n",
    "ind = subjects[subj]\n",
    "print(ind)\n",
    "subject_folder = [subject_folder[subj]]\n",
    "print(subject_folder)\n",
    "ind_i = subj\n",
    "\n",
    "error_msg = \"All paths successfully calculated.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightpink = np.array([256 / 256, 128 / 256, 178 / 256, 1.0])\n",
    "cyan = np.array([1 / 256, 256 / 256, 256 / 256, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load face localizers here ###\n",
    "##################################\n",
    "try:\n",
    "    if subj == 0:\n",
    "        folder_spmT_f = 'dummy_data/one_hander/'+ind+'_face_win_thrs_left_orig_70.vtk'\n",
    "        print(folder_spmT_f)\n",
    "    else:\n",
    "        folder_spmT_f = 'dummy_data/one_hander/'+ind+'_face_win_thrs_right_orig_70.vtk'\n",
    "\n",
    "    # initialize mesh #\n",
    "    mesh_f = pv.read(folder_spmT_f)\n",
    "\n",
    "    # initilaize color mapping #\n",
    "    mapping_f = np.linspace(mesh_f['EmbedVertex'].min(), mesh_f['EmbedVertex'].max(), 256)\n",
    "    newcolors_f = np.empty((256, 4))\n",
    "    newcolors_f[mapping_f > 0.01] = cyan\n",
    "    newcolors_f[mapping_f < 0.01] = white\n",
    "\n",
    "    my_colormap_f = ListedColormap(newcolors_f)\n",
    "except:\n",
    "    print(\"No face localizer.\")\n",
    "    \n",
    "### load hand localizers here ###\n",
    "#################################\n",
    "try:\n",
    "    if subj == 0:\n",
    "        folder_spmT_h = 'dummy_data/one_hander/'+ind+'_hand_win_thrs_left_orig_70.vtk'\n",
    "    else:\n",
    "        folder_spmT_h = 'dummy_data/one_hander/'+ind+'_hand_win_thrs_right_orig_70.vtk'\n",
    "    #os.chdir(folder_spmT_h)\n",
    "    #filename_spmT_h = glob.glob('*_hand_S1_smoothdata.vtk')\n",
    "\n",
    "    # initilaize mesh #\n",
    "    mesh_h = pv.read(folder_spmT_h)\n",
    "\n",
    "    # intialize color mapping #\n",
    "    mapping_h = np.linspace(mesh_h['EmbedVertex'].min(), mesh_h['EmbedVertex'].max(), 256)\n",
    "    newcolors_h = np.empty((256, 4))\n",
    "    newcolors_h[mapping_h > 0] = lightpink\n",
    "    newcolors_h[mapping_h < 0] = white\n",
    "\n",
    "    my_colormap_h = ListedColormap(newcolors_h)\n",
    "except:\n",
    "    print(\"No hand localizer.\")\n",
    "\n",
    "### load qT1 Maps ###\n",
    "#####################\n",
    "folder_qT1 = 'dummy_data/one_hander/'\n",
    "smooth_folder_qT1 = 'dummy_data/one_hander/'\n",
    "\n",
    "os.chdir(folder_qT1)\n",
    "if subj == 0:\n",
    "    filename_qT1_dp = subjects[ind_i]+'_qT1_S1_inner_DDlayers_left_orig.vtk'\n",
    "    filename_qT1_im = subjects[ind_i]+'_qT1_S1_middle_DDlayers_left_orig.vtk'\n",
    "    filename_qT1_om = subjects[ind_i]+'_qT1_S1_outer_DDlayers_left_orig.vtk'\n",
    "else:\n",
    "    filename_qT1_dp = subjects[ind_i]+'_qT1_S1_inner_DDlayers_right_orig.vtk'\n",
    "    filename_qT1_im = subjects[ind_i]+'_qT1_S1_middle_DDlayers_right_orig.vtk'\n",
    "    filename_qT1_om = subjects[ind_i]+'_qT1_S1_outer_DDlayers_right_orig.vtk'\n",
    "    \n",
    "os.chdir(smooth_folder_qT1)\n",
    "smooth_filename_qT1_im = glob.glob('*_smoothdata.vtk')\n",
    "\n",
    "# read in poly data #\n",
    "mesh_qT1_dp = pv.read(folder_qT1+filename_qT1_dp)\n",
    "mesh_qT1_im = pv.read(folder_qT1+filename_qT1_im)\n",
    "smooth_mesh_qT1_im = pv.read(smooth_folder_qT1+smooth_filename_qT1_im[0])\n",
    "mesh_qT1_om = pv.read(folder_qT1+filename_qT1_om)\n",
    "\n",
    "### load full data array with spmT finger peak values ###\n",
    "#########################################################\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "if subj==0:\n",
    "    filename_qT1_S1_full_dict = scipy.io.loadmat('dummy_data/one_hander/'+ind+'_body_part_win_S1_thrs_left_orig_70.mat')\n",
    "    tmp_hand = scipy.io.loadmat('dummy_data/one_hander/'+ind+'_T1_mhand_DDlayer_thrs_left_orig_70.mat')\n",
    "    tmp_face = scipy.io.loadmat('dummy_data/one_hander/'+ind+'_T1_mface_DDlayer_thrs_left_orig_70.mat')\n",
    "    \n",
    "    filename_qT1_S1_full = filename_qT1_S1_full_dict['finger_winner_S1']\n",
    "    print(filename_qT1_S1_full)\n",
    "    \n",
    "    print(tmp_hand)\n",
    "    tmp_handvals = tmp_hand['T1_D1']\n",
    "    print(tmp_handvals)\n",
    "    \n",
    "    print(tmp_face)\n",
    "    tmp_facevals = tmp_face['T1_D2']\n",
    "    \n",
    "    filename_qT1_S1_full = np.concatenate((filename_qT1_S1_full,tmp_handvals,tmp_facevals))\n",
    "    print(filename_qT1_S1_full)\n",
    "    \n",
    "    filename_d1 = 'dummy_data/one_hander/'+ind+'_hand_win_thrs_left_orig_70.vtk'\n",
    "    filename_d2 = 'dummy_data/one_hander/'+ind+'_face_win_thrs_left_orig_70.vtk'\n",
    "else:\n",
    "    filename_qT1_S1_full_dict = scipy.io.loadmat('dummy_data/one_hander/'+ind+'_body_part_win_S1_thrs_right_orig_70.mat')\n",
    "    tmp_hand = scipy.io.loadmat('dummy_data/one_hander/'+ind+'_T1_mhand_DDlayer_thrs_right_orig_70.mat')\n",
    "    tmp_face = scipy.io.loadmat('dummy_data/one_hander/'+ind+'_T1_mface_DDlayer_thrs_right_orig_70.mat')\n",
    "    \n",
    "    filename_qT1_S1_full = filename_qT1_S1_full_dict['finger_winner_S1']\n",
    "    print(filename_qT1_S1_full)\n",
    "    \n",
    "    print(tmp_hand)\n",
    "    tmp_handvals = tmp_hand['T1_D1']\n",
    "    print(tmp_handvals)\n",
    "    \n",
    "    print(tmp_face)\n",
    "    tmp_facevals = tmp_face['T1_D2']\n",
    "    \n",
    "    filename_qT1_S1_full = np.concatenate((filename_qT1_S1_full,tmp_handvals,tmp_facevals))\n",
    "    print(filename_qT1_S1_full)\n",
    "    \n",
    "    filename_d1 = 'dummy_data/one_hander/'+ind+'_hand_win_thrs_right_orig_70.vtk'\n",
    "    filename_d2 = 'dummy_data/one_hander/'+ind+'_face_win_thrs_right_orig_70.vtk'\n",
    "\n",
    "# read in file that contains extracted values after applying winner-takes-all approach\n",
    "qT1_S1_full = filename_qT1_S1_full\n",
    "\n",
    "#read in pRF surfaces for plotting\n",
    "##################################\n",
    "\n",
    "mesh_d1 = pv.read(filename_d1)\n",
    "mesh_d2 = pv.read(filename_d2)\n",
    "\n",
    "### specify results folder ###\n",
    "##############################\n",
    "if subj==0:\n",
    "    outdir='dummy_data/one_hander/results/septa/v8/'\n",
    "    outdir_all='dummy_data/one_hander/results/septa/v8/'\n",
    "else:\n",
    "    outdir='dummy_data/one_hander/results/septa/v8/right'\n",
    "    outdir_all='dummy_data/one_hander/results/septa/v8/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate binary BA3b mask #\n",
    "tmp = mesh_qT1_im\n",
    "tmp0 = tmp['EmbedVertex']\n",
    "tmp0[tmp0>0] = 1\n",
    "tmp['EmbedVertex'] = tmp0\n",
    "\n",
    "# apply binary BA3b mask to smoothed maps #\n",
    "tmp1=smooth_mesh_qT1_im\n",
    "tmp2=tmp1['EmbedVertex']*tmp['EmbedVertex']\n",
    "#tmp1['EmbedVertex']=tmp2\n",
    "smooth_mesh_qT1_im['EmbedVertex']=tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract mean and sd from qT1 surface\n",
    "######################################\n",
    "vtx_mesh_qT1_im = smooth_mesh_qT1_im['EmbedVertex']\n",
    "\n",
    "print(vtx_mesh_qT1_im.max())\n",
    "\n",
    "print(vtx_mesh_qT1_im[np.nonzero(vtx_mesh_qT1_im)])\n",
    "\n",
    "vtx_mesh_qT1_im_omitzero = vtx_mesh_qT1_im[np.nonzero(vtx_mesh_qT1_im)]\n",
    "\n",
    "mean_im = vtx_mesh_qT1_im_omitzero.mean()\n",
    "sd_im = vtx_mesh_qT1_im_omitzero.std()\n",
    "\n",
    "print(mean_im)\n",
    "print(sd_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot smoothed qT1 values restricted to BA3b\n",
    "#############################################\n",
    "qT1_cmap = cmocean.cm.turbid_r\n",
    "if subj==0:\n",
    "    p4_camera_position = [(235.22052780809193, 39.8387107829154, -139.23390663890612),(23.55722029834093, 79.19966881614376, 65.00208781014945),(-0.6493875573065231, -0.494533993462862, -0.57769536065745)]\n",
    "else:\n",
    "    p4_camera_position = [(-241.809, 8.5008, -79.353),(29.1759, 82.2512, 61.8365),(0.86209, -0.234624, -0.449169)]\n",
    "p = pv.Plotter()\n",
    "#p.add_mesh(tmp1, cmap=qT1_cmap, clim=[mean_dp-(4*sd_dp), mean_dp+(4*sd_dp)],below_color=\"#ffffff\")\n",
    "p.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p.camera_position = p4_camera_position\n",
    "p.show()\n",
    "\n",
    "## should you experience 'vtkxopenglrenderwindow could not find a decent config' error at this stage, shut down jupyter notebooks and type the following command in your terminal:\n",
    "## export LD_PRELOAD='/usr/lib/x86_64-linux-gnu/libstdc++.so.6'\n",
    "## restart jupyter notebook and run again from the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract mean and sd from qT1 surface\n",
    "######################################\n",
    "mesh_qT1_dp = pv.read(folder_qT1+filename_qT1_dp)\n",
    "vtx_mesh_qT1_dp = mesh_qT1_dp['EmbedVertex']\n",
    "\n",
    "print(vtx_mesh_qT1_dp.max())\n",
    "\n",
    "print(vtx_mesh_qT1_dp[np.nonzero(vtx_mesh_qT1_dp)])\n",
    "\n",
    "vtx_mesh_qT1_dp_omitzero = vtx_mesh_qT1_dp[np.nonzero(vtx_mesh_qT1_dp)]\n",
    "\n",
    "mean_dp = vtx_mesh_qT1_dp_omitzero.mean()\n",
    "sd_dp = vtx_mesh_qT1_dp_omitzero.std()\n",
    "\n",
    "print(mean_dp)\n",
    "print(sd_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_qT1_im = pv.read(folder_qT1+filename_qT1_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize color mapping\n",
    "##########################\n",
    "mapping_bg = np.linspace(mesh_qT1_dp['EmbedVertex'].min(), mesh_qT1_dp['EmbedVertex'].max(), 256)\n",
    "newcolors_bg = np.empty((256, 4))\n",
    "newcolors_bg[mapping_bg >= 0] = white\n",
    "\n",
    "# pRF maps #\n",
    "mapping_d1 = np.linspace(mesh_d1['EmbedVertex'].min(), mesh_d1['EmbedVertex'].max(), 256)\n",
    "newcolors = np.empty((256, 4))\n",
    "newcolors[mapping_d1 > 0] = red\n",
    "newcolors[mapping_d1 <= 0] = white\n",
    "\n",
    "mapping_d2 = np.linspace(mesh_d2['EmbedVertex'].min(), mesh_d2['EmbedVertex'].max(), 256)\n",
    "newcolors_d2 = np.empty((256, 4))\n",
    "newcolors_d2[mapping_d2 > 0] = magenta\n",
    "newcolors_d2[mapping_d2 <= 0] = white\n",
    "\n",
    "#mapping_d3 = np.linspace(mesh_d3['EmbedVertex'].min(), mesh_d3['EmbedVertex'].max(), 256)\n",
    "#newcolors_d3 = np.empty((256, 4))\n",
    "#newcolors_d3[mapping_d3 > 0] = blue\n",
    "#newcolors_d3[mapping_d3 <= 0] = white\n",
    "\n",
    "#mapping_d4 = np.linspace(mesh_d4['EmbedVertex'].min(), mesh_d4['EmbedVertex'].max(), 256)\n",
    "#newcolors_d4 = np.empty((256, 4))\n",
    "#newcolors_d4[mapping_d4 > 0] = green\n",
    "#newcolors_d4[mapping_d4 <= 0] = white\n",
    "\n",
    "#mapping_d5 = np.linspace(mesh_d5['EmbedVertex'].min(), mesh_d5['EmbedVertex'].max(), 256)\n",
    "#newcolors_d5 = np.empty((256, 4))\n",
    "#newcolors_d5[mapping_d5 > 0] = yellow\n",
    "#newcolors_d5[mapping_d5 <= 0] = white\n",
    "\n",
    "# spmT maps #\n",
    "#mapping_spmT_d1 = np.linspace(0, mesh_spmT_d1['EmbedVertex'].max(), 256)\n",
    "#newcolors_spmT = np.empty((256, 4))\n",
    "#newcolors_spmT[mapping_spmT_d1 > 0] = red\n",
    "#newcolors_spmT[mapping_spmT_d1 <= 0] = white\n",
    "\n",
    "#mapping_spmT_d2 = np.linspace(0, mesh_spmT_d2['EmbedVertex'].max(), 256)\n",
    "#newcolors_spmT_d2 = np.empty((256, 4))\n",
    "#newcolors_spmT_d2[mapping_spmT_d2 > 0] = magenta\n",
    "#newcolors_spmT_d2[mapping_spmT_d2 <= 0] = white\n",
    "\n",
    "#mapping_spmT_d3 = np.linspace(0, mesh_spmT_d3['EmbedVertex'].max(), 256)\n",
    "#newcolors_spmT_d3 = np.empty((256, 4))\n",
    "#newcolors_spmT_d3[mapping_spmT_d3 > 0] = blue\n",
    "#newcolors_spmT_d3[mapping_spmT_d3 <= 0] = white\n",
    "\n",
    "#mapping_spmT_d4 = np.linspace(0, mesh_spmT_d4['EmbedVertex'].max(), 256)\n",
    "#newcolors_spmT_d4 = np.empty((256, 4))\n",
    "#newcolors_spmT_d4[mapping_spmT_d4 > 0] = green\n",
    "#newcolors_spmT_d4[mapping_spmT_d4 <= 0] = white\n",
    "\n",
    "#mapping_spmT_d5 = np.linspace(0, mesh_spmT_d5['EmbedVertex'].max(), 256)\n",
    "#newcolors_spmT_d5 = np.empty((256, 4))\n",
    "#newcolors_spmT_d5[mapping_spmT_d5 > 0] = yellow\n",
    "#newcolors_spmT_d5[mapping_spmT_d5 <= 0] = white\n",
    "\n",
    "# make the colormap from the listed colors #\n",
    "my_colormap_bg = ListedColormap(newcolors_bg)\n",
    "\n",
    "#my_colormap_spmT_d1 = ListedColormap(newcolors_spmT)\n",
    "#my_colormap_spmT_d2 = ListedColormap(newcolors_spmT_d2)\n",
    "#my_colormap_spmT_d3 = ListedColormap(newcolors_spmT_d3)\n",
    "#my_colormap_spmT_d4 = ListedColormap(newcolors_spmT_d4)\n",
    "#my_colormap_spmT_d5 = ListedColormap(newcolors_spmT_d5)\n",
    "\n",
    "my_colormap_d1 = ListedColormap(newcolors)\n",
    "my_colormap_d2 = ListedColormap(newcolors_d2)\n",
    "#my_colormap_d3 = ListedColormap(newcolors_d3)\n",
    "#my_colormap_d4 = ListedColormap(newcolors_d4)\n",
    "#my_colormap_d5 = ListedColormap(newcolors_d5)\n",
    "\n",
    "# load colormap for qT1 Maps #\n",
    "qT1_cmap = cmocean.cm.turbid_r\n",
    "\n",
    "# load color map for hand / face localizers # \n",
    "body_part = plt.get_cmap('PuOr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hand localizer\n",
    "#####################\n",
    "#if ind_i == 39:\n",
    "#    p4_camera_position = [(235.22052780809193, 39.8387107829154, -139.23390663890612),(33.55722029834093, 69.19966881614376, 75.00208781014945),(-0.8493875573065231, -0.694533993462862, -0.57769536065745)]\n",
    "#else:\n",
    "if subj==0:\n",
    "    p4_camera_position = [(235.22052780809193, 39.8387107829154, -139.23390663890612),(23.55722029834093, 79.19966881614376, 65.00208781014945),(-0.6493875573065231, -0.494533993462862, -0.57769536065745)]\n",
    "else:\n",
    "    p4_camera_position = [(-241.809, 8.5008, -79.353),(29.1759, 75.2512, 52.8365),(0.86209, -0.234624, -0.449169)]\n",
    "\n",
    "p = pv.Plotter()\n",
    "p.set_background('white')\n",
    "try:\n",
    "    p.add_mesh(mesh_h, cmap=\"RdPu\")\n",
    "except:\n",
    "    print(\"No hand localizer.\")\n",
    "p.camera_position = p4_camera_position\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot face localizer\n",
    "#####################\n",
    "#p4_camera_position = [(235.22052780809193, 39.8387107829154, -139.23390663890612),(23.55722029834093, 79.19966881614376, 65.00208781014945),(-0.6493875573065231, -0.494533993462862, -0.57769536065745)]\n",
    "p = pv.Plotter()\n",
    "try:\n",
    "    p.add_mesh(mesh_f, cmap='RdPu')\n",
    "except:\n",
    "    print(\"No face localizer.\")\n",
    "p.camera_position = p4_camera_position\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract different contrast values and store them into one common mesh\n",
    "#######################################################################\n",
    "mesh_qT1_dp_orig = pv.read(folder_qT1+filename_qT1_dp)\n",
    "\n",
    "try:\n",
    "    mesh_qT1_dp['Hand'] = mesh_h['EmbedVertex']\n",
    "    mesh_qT1_dp['Face'] = mesh_f['EmbedVertex']\n",
    "except:\n",
    "    print(\"No hand/face localizer.\")\n",
    "    \n",
    "#mesh_qT1_dp['D1_spmT'] = mesh_spmT_d1['EmbedVertex']\n",
    "#mesh_qT1_dp['D2_spmT'] = mesh_spmT_d2['EmbedVertex']\n",
    "#mesh_qT1_dp['D5_spmT'] = mesh_spmT_d5['EmbedVertex']\n",
    "#mesh_qT1_dp['D1b'] = qT1_S1_full[22]\n",
    "#mesh_qT1_dp['D2b'] = qT1_S1_full[23]\n",
    "#mesh_qT1_dp['D5b'] = qT1_S1_full[26]\n",
    "\n",
    "mesh_qT1_dp['HspmT'] = qT1_S1_full[1]\n",
    "mesh_qT1_dp['FspmT'] = qT1_S1_full[2]\n",
    "mesh_qT1_dp['HmqT1'] = qT1_S1_full[5]\n",
    "mesh_qT1_dp['FmqT1'] = qT1_S1_full[8]\n",
    "mesh_qT1_dp['middleqT1'] = mesh_qT1_im['EmbedVertex']\n",
    "mesh_qT1_dp['smoothmiddleqT1'] = smooth_mesh_qT1_im['EmbedVertex']\n",
    "mesh_qT1_dp['qT1'] = mesh_qT1_dp_orig['EmbedVertex']\n",
    "\n",
    "# reduce mesh to valid vertices (i.e. with vertex value > 0)\n",
    "############################################################\n",
    "vertex_values = mesh_qT1_dp['EmbedVertex']\n",
    "vertex_values[vertex_values<1]=0\n",
    "invalid_vertices = np.where(vertex_values == 0)[0]\n",
    "\n",
    "threshed = mesh_qT1_dp.remove_points(invalid_vertices)\n",
    "\n",
    "print(threshed)\n",
    "print(threshed[0]['qT1'])\n",
    "print(len(threshed[0]['EmbedVertex']))\n",
    "\n",
    "# find location of activation peaks\n",
    "###################################\n",
    "spmT_h_full = threshed[0]['Hand'].argmax()\n",
    "print(spmT_h_full)\n",
    "\n",
    "spmT_f_full = threshed[0]['Face'].argmax()\n",
    "\n",
    "avg_v2v_dist = 0.28\n",
    "\n",
    "distance_f_h = 0\n",
    "\n",
    "distance_d2_d5 = 0\n",
    "\n",
    "# define function that finds the face seed \n",
    "##########################################\n",
    "\n",
    "def get_face_seed(threshed, spmT_h_full, multiplicator,dist):\n",
    "    zf = threshed[0].points[spmT_h_full,2]\n",
    "    yf = threshed[0].points[spmT_h_full,1]\n",
    "    xf = threshed[0].points[spmT_h_full,0]\n",
    "    #zf_min = zf-(avg_v2v_dist*multiplicator)\n",
    "    #zf_max = zf+(avg_v2v_dist*multiplicator)\n",
    "    yf_min = yf-(avg_v2v_dist*multiplicator)\n",
    "    yf_max = yf+(avg_v2v_dist*multiplicator)\n",
    "    xf_min = xf-(avg_v2v_dist*multiplicator)\n",
    "    xf_max = xf+(avg_v2v_dist*multiplicator)\n",
    "    #print(zf_max)\n",
    "    #print(zf_min)\n",
    "\n",
    "    zf_multi = np.where((threshed[0].points[:,0]<xf_max) & (threshed[0].points[:,0]>xf_min) & (threshed[0].points[:,1]<yf_max) & (threshed[0].points[:,1]>yf_min) & (threshed[0].points[:,2]>zf) & (threshed[0]['qT1']>1000))\n",
    "    print(zf_multi[0])\n",
    "\n",
    "    distance = []\n",
    "\n",
    "    for zfm in zf_multi[0]:\n",
    "        #print(zfm)\n",
    "        #print(spmT_h_full)\n",
    "        #print('test')\n",
    "        distance.append(threshed[0].geodesic_distance(zfm, spmT_h_full))\n",
    "\n",
    "    distance_diff = abs(np.array(distance) - dist)\n",
    "    distance_idx = distance_diff.argmin()\n",
    "\n",
    "    spmT_f_full = zf_multi[0][distance_idx]\n",
    "\n",
    "    #print(spmT_f_full)\n",
    "    \n",
    "    distance_f_h = threshed[0].geodesic_distance(spmT_f_full, spmT_h_full)\n",
    "    \n",
    "    print(distance_f_h)     \n",
    "    \n",
    "    return zf_multi, spmT_f_full, distance_f_h\n",
    "\n",
    "# define function that finds a seed near the superior border of the hand representation (where the little finger would be located)\n",
    "#################################################################################################################################\n",
    "\n",
    "def get_d5_seed(threshed, spmT_h_full, multiplicator, dist):\n",
    "    zf = threshed[0].points[spmT_h_full,2]\n",
    "    yf = threshed[0].points[spmT_h_full,1]\n",
    "    xf = threshed[0].points[spmT_h_full,0]\n",
    "    #zf_min = zf-(avg_v2v_dist*multiplicator)\n",
    "    #zf_max = zf+(avg_v2v_dist*multiplicator)\n",
    "    yf_min = yf-(avg_v2v_dist*multiplicator)\n",
    "    yf_max = yf+(avg_v2v_dist*multiplicator)\n",
    "    xf_min = xf-(avg_v2v_dist*multiplicator)\n",
    "    xf_max = xf+(avg_v2v_dist*multiplicator)\n",
    "    #print(zf_max)\n",
    "    #print(zf_min)\n",
    "\n",
    "    zf_multi = np.where((threshed[0].points[:,0]<xf_max) & (threshed[0].points[:,0]>xf_min) & (threshed[0].points[:,1]<yf_max) & (threshed[0].points[:,1]>yf_min) & (threshed[0].points[:,2]<zf) & (threshed[0]['qT1']>1000))\n",
    "    print(zf_multi[0])\n",
    "\n",
    "    distance = []\n",
    "\n",
    "    for zfm in zf_multi[0]:\n",
    "        #print(zfm)\n",
    "        #print(spmT_h_full)\n",
    "        #print('test')\n",
    "        distance.append(threshed[0].geodesic_distance(spmT_h_full, zfm))\n",
    "\n",
    "    distance_diff = abs(np.array(distance) - dist)\n",
    "    distance_idx = distance_diff.argmin()\n",
    "\n",
    "    #spmT_d5_full = zf_multi[0][distance_idx]\n",
    "\n",
    "    #print(spmT_f_full)\n",
    "    \n",
    "    distance_d5_d5new = threshed[0].geodesic_distance(spmT_h_full, zf_multi[0][distance_idx])\n",
    "    \n",
    "    print(distance_d5_d5new)\n",
    "    \n",
    "    spmT_d5_full_old = spmT_h_full\n",
    "    \n",
    "    spmT_d5_full = zf_multi[0][distance_idx]\n",
    "    \n",
    "    return zf_multi, spmT_d5_full, distance_d5_d5new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function to define face seed and set distance for geodesic path\n",
    "######################################################################\n",
    "\n",
    "# the max distance was set to 15 mm to ensure that the path (starting at the activation peak of the hand representation) reaches the superior face representation (here the face representation was localized by tongue movements)\n",
    "# otherwise the hand-face border may not have been covered (forehead lies appr. 10 mm inferior to the thumb representation)\n",
    "\n",
    "# needs to be optimized in future versions to target the forehead area more precisely (e.g. extracting the inferior border of the hand representation and sampling precisely 10 mm in inferior direction, or using a forehead localizer)\n",
    "\n",
    "dist = 15\n",
    "    \n",
    "multiplicator = dist\n",
    "\n",
    "while distance_f_h < dist-0.1:\n",
    "    print('testtest')\n",
    "    zf_multi, spmT_f_full, distance_f_h = get_face_seed(threshed, spmT_h_full, multiplicator, dist)\n",
    "    multiplicator = multiplicator + dist\n",
    "    if 0 in zf_multi[0]:\n",
    "        dist = distance_f_h\n",
    "\n",
    "if subj==1:\n",
    "    dist = 17.5\n",
    "    \n",
    "    multiplicator = dist\n",
    "    \n",
    "    spmT_h_full = spmT_f_full\n",
    "    print(spmT_h_full)\n",
    "    \n",
    "    spmT_d5_full = threshed[0]['Hand'].argmax()\n",
    "    print(spmT_d5_full)\n",
    "    \n",
    "    distance_f_h = 0\n",
    "    \n",
    "    while distance_f_h < dist-0.1:\n",
    "        print('testtest')\n",
    "        zf_multi, spmT_f_full, distance_f_h = get_face_seed(threshed, spmT_h_full, multiplicator, dist)\n",
    "        multiplicator = multiplicator + dist\n",
    "        if 0 in zf_multi[0]:\n",
    "            dist = distance_f_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function to define the seed at the superior hand map border and set distance for geodesic path\n",
    "#####################################################################################################\n",
    "\n",
    "# the max distance was set to 7 mm to ensure that the path (starting at the activation peak of the hand representation) reaches the superior part of the hand representation (approximating the superior border)\n",
    "# otherwise the hand representation may not have been fully covered\n",
    "\n",
    "# needs to be optimized (e.g. using xyz coordinates in combination with statistical values to find the superior border of the hand representation)\n",
    "\n",
    "dist = 7\n",
    "    \n",
    "multiplicator = dist\n",
    "\n",
    "if subj==0:\n",
    "    while distance_d2_d5 < dist-0.1:\n",
    "        print('testtest')\n",
    "        zf_d5_multi, spmT_d5_full, distance_d2_d5 = get_d5_seed(threshed, spmT_h_full, multiplicator, dist)\n",
    "        multiplicator = multiplicator + dist\n",
    "        if 0 in zf_d5_multi[0]:\n",
    "            dist = distance_d2_d5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract geodesic paths between activation peaks\n",
    "#################################################\n",
    "path_f_h_full = threshed[0].geodesic(spmT_f_full, spmT_h_full)\n",
    "distance_f_h = threshed[0].geodesic_distance(spmT_f_full, spmT_h_full)\n",
    "print(distance_f_h)\n",
    "\n",
    "path_d2_d5_full = threshed[0].geodesic(spmT_h_full, spmT_d5_full)\n",
    "distance_d2_d5 = threshed[0].geodesic_distance(spmT_h_full, spmT_d5_full)\n",
    "print(distance_d2_d5)\n",
    "\n",
    "#path_d2_d5_full_old = threshed[0].geodesic(spmT_d2_full, spmT_d5_full_old)\n",
    "#distance_d2_d5_old = threshed[0].geodesic_distance(spmT_d2_full, spmT_d5_full_old)\n",
    "#print(distance_d2_d5_old)\n",
    "\n",
    "# extract deep qT1 values along geodesic paths\n",
    "##############################################\n",
    "qT1_dp_path_f_h_full = threshed[0]['qT1'][path_f_h_full['vtkOriginalPointIds']]\n",
    "qT1_dp_path_d2_d5_full = threshed[0]['qT1'][path_d2_d5_full['vtkOriginalPointIds']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract start and end points of geodesic paths (activation peaks of functional localizers)\n",
    "############################################################################################\n",
    "extracted_f = path_f_h_full.extract_points(0, adjacent_cells=False, include_cells=False)\n",
    "extracted_h = path_d2_d5_full.extract_points(0, adjacent_cells=False, include_cells=False)\n",
    "extracted_d5 = path_d2_d5_full.extract_points(len(path_d2_d5_full['vtkOriginalPointIds'])-1, adjacent_cells=False, include_cells=False)\n",
    "#extracted_d5_old = path_d2_d5_full_old.extract_points(len(path_d2_d5_full_old['vtkOriginalPointIds'])-1, adjacent_cells=False, include_cells=False)\n",
    "\n",
    "print(extracted_f)\n",
    "print(extracted_h)\n",
    "print(extracted_d5)\n",
    "\n",
    "merged_path = path_f_h_full.merge(path_d2_d5_full)\n",
    "print(merged_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract geodesic distances from face to D5\n",
    "################################################################################\n",
    "distance_f_h_all = [0]\n",
    "\n",
    "distance_d2_d5_all = [0]\n",
    "\n",
    "i = 0\n",
    "\n",
    "for i in range(len(path_f_h_full['vtkOriginalPointIds'])-1):\n",
    "    cur_dist = threshed[0].geodesic_distance(path_f_h_full['vtkOriginalPointIds'][0], path_f_h_full['vtkOriginalPointIds'][i+1])\n",
    "    distance_f_h_all.append(cur_dist)\n",
    "\n",
    "print(len(distance_f_h_all))\n",
    "\n",
    "for i in range(len(path_d2_d5_full['vtkOriginalPointIds'])-1):\n",
    "    cur_dist = threshed[0].geodesic_distance(path_d2_d5_full['vtkOriginalPointIds'][0], path_d2_d5_full['vtkOriginalPointIds'][i+1])\n",
    "    distance_d2_d5_all.append(cur_dist)\n",
    "\n",
    "print(len(distance_d2_d5_all))\n",
    "\n",
    "distance_d2_d5_all_fin = distance_d2_d5_all \n",
    "\n",
    "print(len(distance_d2_d5_all_fin))\n",
    "print(distance_d2_d5_all_fin)\n",
    "\n",
    "# calculate average vertex-to-vertex distance of individual participant\n",
    "distance_f_h_all_diff = np.sum(np.diff(distance_f_h_all))/len(np.diff(distance_f_h_all))\n",
    "print(distance_f_h_all_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract vertex from face localizer that is located 10 mm away from D1 peak along the shortest path between D1 peak and Face peak\n",
    "####################################################################################################################\n",
    "# this is important to approxiamte the location of the forehead within the face map which neighbors the thumb representation \n",
    "distance_f_h_all_rev = np.array(distance_f_h_all) - np.max(distance_f_h_all)\n",
    "\n",
    "extracted_fd10 = path_f_h_full.extract_points(0, adjacent_cells=False, include_cells=False)\n",
    "print(extracted_fd10)\n",
    "#print(path_f_h_full['vtkOriginalPointIds'][dist_10])\n",
    "\n",
    "extracted_fd10_idx = list(range(0,len(distance_f_h_all)+1))\n",
    "print(extracted_fd10_idx)\n",
    "print(path_f_h_full)\n",
    "\n",
    "path_d1_dist10 = path_f_h_full.extract_points(extracted_fd10_idx,adjacent_cells=False,include_cells=False)\n",
    "path_d1_dist10_origIDs = path_f_h_full['vtkOriginalPointIds'][0:len(distance_f_h_all)+1]\n",
    "#print(path_d1_dist10)\n",
    "print(path_f_h_full['vtkOriginalPointIds'])\n",
    "print(path_d1_dist10_origIDs)\n",
    "\n",
    "distance_f_h_all_rev_d10 = distance_f_h_all_rev[0:len(distance_f_h_all)+1]\n",
    "print(distance_f_h_all_rev_d10)\n",
    "\n",
    "spmT_f = path_f_h_full['vtkOriginalPointIds'][0]\n",
    "print(spmT_f)\n",
    "#print(spmT_f_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract multiple start and end points\n",
    "#######################################\n",
    "# thumb\n",
    "yh = threshed[0].points[spmT_h_full,1]\n",
    "xh = threshed[0].points[spmT_h_full,0]\n",
    "print(yh)\n",
    "yh_min = yh-(avg_v2v_dist/2)\n",
    "yh_max = yh+(avg_v2v_dist/2)\n",
    "xh_min = xh-(avg_v2v_dist/2)\n",
    "xh_max = xh+(avg_v2v_dist/2)\n",
    "print(yh_max)\n",
    "print(xh_max)\n",
    "yh_multi = np.where((threshed[0].points[:,1]>yh_min) & (threshed[0].points[:,1]<yh_max) & (threshed[0]['qT1']>1000))\n",
    "xh_multi = np.where((threshed[0].points[:,0]>xh_min) & (threshed[0].points[:,0]<xh_max) & (threshed[0]['qT1']>1000))\n",
    "print(yh_multi)\n",
    "print(xh_multi)\n",
    "print(len(yh_multi[0]))\n",
    "print(len(xh_multi[0]))\n",
    "\n",
    "yh_multi_yval = np.argsort(threshed[0].points[yh_multi[0],0])\n",
    "yh_multi_yidx = np.take_along_axis(yh_multi[0],yh_multi_yval,axis=0)\n",
    "print(yh_multi_yval)\n",
    "print(yh_multi_yidx)\n",
    "\n",
    "xh_multi_yval = np.argsort(threshed[0].points[xh_multi[0],1])\n",
    "xh_multi_yidx = np.take_along_axis(xh_multi[0],xh_multi_yval,axis=0)\n",
    "print(xh_multi_yval)\n",
    "print(xh_multi_yidx)\n",
    "\n",
    "test_yh = threshed[0].extract_points(yh_multi,adjacent_cells=False, include_cells=False)\n",
    "test_xh = threshed[0].extract_points(xh_multi,adjacent_cells=False, include_cells=False)\n",
    "\n",
    "# face\n",
    "yf = threshed[0].points[spmT_f,1]\n",
    "xf = threshed[0].points[spmT_f,0]\n",
    "print(yf)\n",
    "yf_min = yf-(avg_v2v_dist/2)\n",
    "yf_max = yf+(avg_v2v_dist/2)\n",
    "xf_min = xf-(avg_v2v_dist/2)\n",
    "xf_max = xf+(avg_v2v_dist/2)\n",
    "print(yf_max)\n",
    "print(xf_max)\n",
    "yf_multi = np.where((threshed[0].points[:,1]>yf_min) & (threshed[0].points[:,1]<yf_max) & (threshed[0]['qT1']>1000))\n",
    "xf_multi = np.where((threshed[0].points[:,0]>xf_min) & (threshed[0].points[:,0]<xf_max) & (threshed[0]['qT1']>1000))\n",
    "print(yf_multi[0])\n",
    "print(xf_multi[0])\n",
    "\n",
    "yf_multi_yval = np.argsort(threshed[0].points[yf_multi[0],0])\n",
    "yf_multi_yidx = np.take_along_axis(yf_multi[0],yf_multi_yval,axis=0)\n",
    "print(yf_multi_yval)\n",
    "print(yf_multi_yidx)\n",
    "\n",
    "xf_multi_yval = np.argsort(threshed[0].points[xf_multi[0],1])\n",
    "xf_multi_yidx = np.take_along_axis(xf_multi[0],xf_multi_yval,axis=0)\n",
    "print(xf_multi_yval)\n",
    "print(xf_multi_yidx)\n",
    "\n",
    "test_yf = threshed[0].extract_points(yf_multi,adjacent_cells=False, include_cells=False)\n",
    "test_xf = threshed[0].extract_points(xf_multi,adjacent_cells=False, include_cells=False)\n",
    "\n",
    "# little finger\n",
    "yd5 = threshed[0].points[spmT_d5_full,1]\n",
    "xd5 = threshed[0].points[spmT_d5_full,0]\n",
    "print(yd5)\n",
    "yd5_min = yd5-(avg_v2v_dist/2)\n",
    "yd5_max = yd5+(avg_v2v_dist/2)\n",
    "xd5_min = xd5-(avg_v2v_dist/2)\n",
    "xd5_max = xd5+(avg_v2v_dist/2)\n",
    "print(yd5_max)\n",
    "print(xd5_max)\n",
    "yd5_multi = np.where((threshed[0].points[:,1]>yd5_min) & (threshed[0].points[:,1]<yd5_max) & (threshed[0]['qT1']>1000))\n",
    "xd5_multi = np.where((threshed[0].points[:,0]>xd5_min) & (threshed[0].points[:,0]<xd5_max) & (threshed[0]['qT1']>1000))\n",
    "print(yd5_multi[0])\n",
    "print(xd5_multi[0])\n",
    "\n",
    "yd5_multi_yval = np.argsort(threshed[0].points[yd5_multi[0],0])\n",
    "yd5_multi_yidx = np.take_along_axis(yd5_multi[0],yd5_multi_yval,axis=0)\n",
    "print(yd5_multi_yval)\n",
    "print(yd5_multi_yidx)\n",
    "\n",
    "xd5_multi_yval = np.argsort(threshed[0].points[xd5_multi[0],1])\n",
    "xd5_multi_yidx = np.take_along_axis(xd5_multi[0],xd5_multi_yval,axis=0)\n",
    "print(xd5_multi_yval)\n",
    "print(xd5_multi_yidx)\n",
    "\n",
    "test_yd5 = threshed[0].extract_points(yd5_multi,adjacent_cells=False, include_cells=False)\n",
    "test_xd5 = threshed[0].extract_points(xd5_multi,adjacent_cells=False, include_cells=False)\n",
    "\n",
    "# extract multiple equally-spaced start and end points along y-axis\n",
    "###################################################################\n",
    "test_yh_num = int(len(yh_multi[0])/5)\n",
    "print(test_yh_num)\n",
    "test_yh_offset = int((int((len(yh_multi[0])-(test_yh_num*5)))+test_yh_num)/2)\n",
    "print(test_yh_offset)\n",
    "test_yh_red = threshed[0].extract_points(yh_multi_yidx[test_yh_offset::test_yh_num],adjacent_cells=False, include_cells=False)\n",
    "yh_multi_red = yh_multi_yidx[test_yh_offset::test_yh_num]\n",
    "yh_multi_red_sort_keys = np.argsort(threshed[0].points[yh_multi_red,0]) \n",
    "yh_multi_red_sort = np.take_along_axis(yh_multi_red,yh_multi_red_sort_keys,axis=0) \n",
    "print(yh_multi_red)\n",
    "print(yh_multi_red_sort)\n",
    "print(yh_multi_red_sort_keys)\n",
    "\n",
    "test_yf_num = int(len(yf_multi[0])/5)\n",
    "print(test_yf_num)\n",
    "test_yf_offset = int((int((len(yf_multi[0])-(test_yf_num*5)))+test_yf_num)/2)\n",
    "print(test_yf_offset)\n",
    "test_yf_red = threshed[0].extract_points(yf_multi_yidx[test_yf_offset::test_yf_num],adjacent_cells=False, include_cells=False)\n",
    "yf_multi_red = yf_multi_yidx[test_yf_offset::test_yf_num]\n",
    "yf_multi_red_sort_keys = np.argsort(threshed[0].points[yf_multi_red,0]) \n",
    "yf_multi_red_sort = np.take_along_axis(yf_multi_red,yf_multi_red_sort_keys,axis=0) \n",
    "print(yf_multi_red)\n",
    "print(threshed[0].points[yf_multi_red,1])\n",
    "print(yf_multi_red_sort)\n",
    "print(yf_multi_red_sort_keys)\n",
    "\n",
    "test_yd5_num = int(len(yd5_multi[0])/5)\n",
    "print(test_yd5_num)\n",
    "test_yd5_offset = int((int((len(yd5_multi[0])-(test_yd5_num*5)))+test_yd5_num)/2)\n",
    "print(test_yd5_offset)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "test_yd5_red = threshed[0].extract_points(yd5_multi_yidx[test_yd5_offset::test_yd5_num],adjacent_cells=False, include_cells=False)\n",
    "print(test_yd5_red)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "yd5_multi_red = yd5_multi_yidx[test_yd5_offset::test_yd5_num]\n",
    "yd5_multi_red_sort_keys = np.argsort(threshed[0].points[yd5_multi_red,0]) \n",
    "yd5_multi_red_sort = np.take_along_axis(yd5_multi_red,yd5_multi_red_sort_keys,axis=0) \n",
    "print(yd5_multi_red)\n",
    "print(threshed[0].points[yd5_multi_red,1])\n",
    "print(yd5_multi_red_sort)\n",
    "print(yd5_multi_red_sort_keys)\n",
    "\n",
    "# extract multiple equally-spaced start and end points along x-axis\n",
    "###################################################################\n",
    "test_xh_num = int(len(xh_multi[0])/5)\n",
    "print(test_xh_num)\n",
    "test_xh_offset = int((int((len(xh_multi[0])-(test_xh_num*5)))+test_xh_num)/2)\n",
    "print(test_xh_offset)\n",
    "test_xh_red = threshed[0].extract_points(xh_multi_yidx[test_xh_offset::test_xh_num],adjacent_cells=False, include_cells=False)\n",
    "xh_multi_red = xh_multi_yidx[test_xh_offset::test_xh_num]\n",
    "xh_multi_red_sort_keys = np.argsort(threshed[0].points[xh_multi_red,1]) \n",
    "xh_multi_red_sort = np.take_along_axis(xh_multi_red,xh_multi_red_sort_keys,axis=0) \n",
    "print(xh_multi_red)\n",
    "print(xh_multi_red_sort)\n",
    "print(xh_multi_red_sort_keys)\n",
    "\n",
    "test_xf_num = int(len(xf_multi[0])/5)\n",
    "print(test_xf_num)\n",
    "test_xf_offset = int((int((len(xf_multi[0])-(test_xf_num*5)))+test_xf_num)/2)\n",
    "print(test_xf_offset)\n",
    "test_xf_red = threshed[0].extract_points(xf_multi_yidx[test_xf_offset::test_xf_num],adjacent_cells=False, include_cells=False)\n",
    "xf_multi_red = xf_multi_yidx[test_xf_offset::test_xf_num]\n",
    "xf_multi_red_sort_keys = np.argsort(threshed[0].points[xf_multi_red,1]) \n",
    "xf_multi_red_sort = np.take_along_axis(xf_multi_red,xf_multi_red_sort_keys,axis=0) \n",
    "print(xf_multi_red)\n",
    "print(threshed[0].points[xf_multi_red,1])\n",
    "print(xf_multi_red_sort)\n",
    "print(xf_multi_red_sort_keys)\n",
    "\n",
    "test_xd5_num = int(len(xd5_multi[0])/5)\n",
    "print(test_xd5_num)\n",
    "test_xd5_offset = int((int((len(xd5_multi[0])-(test_xd5_num*5)))+test_xd5_num)/2)\n",
    "print(test_xd5_offset)\n",
    "test_xd5_red = threshed[0].extract_points(xd5_multi_yidx[test_xd5_offset::test_xd5_num],adjacent_cells=False, include_cells=False)\n",
    "xd5_multi_red = xd5_multi_yidx[test_xd5_offset::test_xd5_num]\n",
    "xd5_multi_red_sort_keys = np.argsort(threshed[0].points[xd5_multi_red,1]) \n",
    "xd5_multi_red_sort = np.take_along_axis(xd5_multi_red,xd5_multi_red_sort_keys,axis=0) \n",
    "print(xd5_multi_red)\n",
    "print(threshed[0].points[xd5_multi_red,1])\n",
    "print(xd5_multi_red_sort)\n",
    "print(xd5_multi_red_sort_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate shortest paths between extracted start and end points along y-axis\n",
    "##############################################################################\n",
    "# face-D1 paths\n",
    "i = 0\n",
    "path_f_h_full_multi_yred = []\n",
    "distance_f_h_multi_yred = []\n",
    "qT1_dp_path_f_h_full_multi_yred = []\n",
    "\n",
    "for i in range(len(yh_multi_red)):\n",
    "    path_f_h_full_multi_yred.append(threshed[0].geodesic(yf_multi_red_sort[i], yh_multi_red_sort[i]))\n",
    "    distance_f_h_multi_yred.append(threshed[0].geodesic_distance(yf_multi_red_sort[i], yh_multi_red_sort[i]))\n",
    "    qT1_dp_path_f_h_full_multi_yred.append(threshed[0]['qT1'][path_f_h_full_multi_yred[i]['vtkOriginalPointIds']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D2-D5 paths\n",
    "i = 0\n",
    "path_d2_d5_full_multi_yred = []\n",
    "distance_d2_d5_multi_yred = []\n",
    "qT1_dp_path_d2_d5_full_multi_yred = []\n",
    "\n",
    "for i in range(len(yh_multi_red)):\n",
    "    path_d2_d5_full_multi_yred.append(threshed[0].geodesic(yh_multi_red_sort[i], yd5_multi_red_sort[i]))\n",
    "    distance_d2_d5_multi_yred.append(threshed[0].geodesic_distance(yh_multi_red_sort[i], yd5_multi_red_sort[i]))\n",
    "    qT1_dp_path_d2_d5_full_multi_yred.append(threshed[0]['qT1'][path_d2_d5_full_multi_yred[i]['vtkOriginalPointIds']])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate shortest paths between extracted start and end points along x-axis\n",
    "##############################################################################\n",
    "# face-D1 paths\n",
    "\n",
    "i = 0\n",
    "path_f_h_full_multi_xred = []\n",
    "distance_f_h_multi_xred = []\n",
    "qT1_dp_path_f_h_full_multi_xred = []\n",
    "\n",
    "for i in range(len(xh_multi_red)):\n",
    "    path_f_h_full_multi_xred.append(threshed[0].geodesic(xf_multi_red_sort[i], xh_multi_red_sort[i]))\n",
    "    distance_f_h_multi_xred.append(threshed[0].geodesic_distance(xf_multi_red_sort[i], xh_multi_red_sort[i]))\n",
    "    qT1_dp_path_f_h_full_multi_xred.append(threshed[0]['qT1'][path_f_h_full_multi_xred[i]['vtkOriginalPointIds']])\n",
    "    \n",
    "# D5-D5 paths\n",
    "i = 0\n",
    "path_d2_d5_full_multi_xred = []\n",
    "distance_d2_d5_multi_xred = []\n",
    "qT1_dp_path_d2_d5_full_multi_xred = []\n",
    "\n",
    "for i in range(len(xh_multi_red)):\n",
    "    path_d2_d5_full_multi_xred.append(threshed[0].geodesic(xh_multi_red_sort[i], xd5_multi_red_sort[i]))\n",
    "    distance_d2_d5_multi_xred.append(threshed[0].geodesic_distance(xh_multi_red_sort[i], xd5_multi_red_sort[i]))\n",
    "    qT1_dp_path_d2_d5_full_multi_xred.append(threshed[0]['qT1'][path_d2_d5_full_multi_xred[i]['vtkOriginalPointIds']])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project extracted original geod. path to surface and visualize #\n",
    "##################################################################\n",
    "vtx_mesh_qT1_dp = mesh_qT1_dp['EmbedVertex']\n",
    "vtx_mesh_qT1_dp_omitzero = vtx_mesh_qT1_dp[np.nonzero(vtx_mesh_qT1_dp)]\n",
    "mean_dp = vtx_mesh_qT1_dp_omitzero.mean()\n",
    "sd_dp = vtx_mesh_qT1_dp_omitzero.std()\n",
    "\n",
    "print(mean_dp)\n",
    "print(sd_dp)\n",
    "\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "#p4.add_mesh(mesh_qT1_dp, cmap=qT1_cmap, clim=[mean_dp-(4*sd_dp), mean_dp+(4*sd_dp)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(mesh_f, cmap='RdPu')\n",
    "p4.add_mesh(path_d1_dist10, line_width=8, color='k')\n",
    "p4.add_mesh(path_d2_d5_full, line_width=8, color='k')\n",
    "p4.add_mesh(extracted_fd10, point_size=8, color='c')\n",
    "#p4.add_mesh(threshed[0].extract_points(zf_multi[0],adjacent_cells=False, include_cells=False))\n",
    "#p4.add_mesh(threshed[0].extract_points(zd5_multi[0],adjacent_cells=False, include_cells=False))\n",
    "p4.add_mesh(extracted_h, point_size=8, color='r')\n",
    "p4.add_mesh(extracted_d5, point_size=8, color='y')\n",
    "#p4.add_mesh(extracted_d5_old, point_size=8, color='w')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.show()\n",
    "\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(mesh_qT1_dp, cmap=qT1_cmap, clim=[mean_dp-(4*sd_dp), mean_dp+(4*sd_dp)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(path_d1_dist10, line_width=8, color='k')\n",
    "p4.add_mesh(path_d2_d5_full, line_width=8, color='k')\n",
    "p4.add_mesh(extracted_fd10, point_size=8, color='c')\n",
    "p4.add_mesh(extracted_h, point_size=8, color='r')\n",
    "p4.add_mesh(extracted_d5, point_size=8, color='y')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.screenshot(outdir+ind+'_qT1_dp_paths.png',transparent_background = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract geodesic distances for all paths along y-axis\n",
    "#################################################################################################\n",
    "distance_f_h_all_multi_y = [[0],[0],[0],[0],[0]]\n",
    "distance_f_h_all_multi_y_rev = [[0],[0],[0],[0],[0]]\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for i in range(len(path_f_h_full_multi_yred)):\n",
    "    for j in range(len(path_f_h_full_multi_yred[i]['vtkOriginalPointIds'])-1):\n",
    "        cur_dist = threshed[0].geodesic_distance(path_f_h_full_multi_yred[i]['vtkOriginalPointIds'][0], path_f_h_full_multi_yred[i]['vtkOriginalPointIds'][j+1])\n",
    "        distance_f_h_all_multi_y[i].append(cur_dist)\n",
    "    \n",
    "    distance_f_h_all_multi_y_rev[i] = np.array(distance_f_h_all_multi_y[i]) - np.max(distance_f_h_all_multi_y[i])\n",
    "\n",
    "#print(distance_f_h_all_multi_y)\n",
    "print(distance_f_h_all_multi_y_rev)\n",
    "\n",
    "\n",
    "distance_d2_d5_all_multi_y = [[0],[0],[0],[0],[0]]\n",
    "distance_d2_d5_all_multi_y_fin = [[0],[0],[0],[0],[0]]\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for i in range(len(path_d2_d5_full_multi_yred)):\n",
    "    for j in range(len(path_d2_d5_full_multi_yred[i]['vtkOriginalPointIds'])-1):\n",
    "        cur_dist = threshed[0].geodesic_distance(path_d2_d5_full_multi_yred[i]['vtkOriginalPointIds'][0], path_d2_d5_full_multi_yred[i]['vtkOriginalPointIds'][j+1])\n",
    "        distance_d2_d5_all_multi_y[i].append(cur_dist)\n",
    "        \n",
    "    distance_d2_d5_all_multi_y_fin[i] = np.array(distance_d2_d5_all_multi_y[i])\n",
    "    \n",
    "#print(distance_d2_d5_all_multi_y)\n",
    "print(distance_d2_d5_all_multi_y_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract geodesic distances for all paths sampled along x-axis\n",
    "#################################################################################################\n",
    "distance_f_h_all_multi_x = [[0],[0],[0],[0],[0]]\n",
    "distance_f_h_all_multi_x_rev = [[0],[0],[0],[0],[0]]\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for i in range(len(path_f_h_full_multi_xred)):\n",
    "    for j in range(len(path_f_h_full_multi_xred[i]['vtkOriginalPointIds'])-1):\n",
    "        cur_dist = threshed[0].geodesic_distance(path_f_h_full_multi_xred[i]['vtkOriginalPointIds'][0], path_f_h_full_multi_xred[i]['vtkOriginalPointIds'][j+1])\n",
    "        distance_f_h_all_multi_x[i].append(cur_dist)\n",
    "    \n",
    "    distance_f_h_all_multi_x_rev[i] = np.array(distance_f_h_all_multi_x[i]) - np.max(distance_f_h_all_multi_x[i])\n",
    "\n",
    "#print(distance_f_h_all_multi_x)\n",
    "print(distance_f_h_all_multi_x_rev)\n",
    "\n",
    "distance_d2_d5_all_multi_x = [[0],[0],[0],[0],[0]]\n",
    "distance_d2_d5_all_multi_x_fin = [[0],[0],[0],[0],[0]]\n",
    "i = 0\n",
    "j = 0\n",
    "for i in range(len(path_d2_d5_full_multi_xred)):\n",
    "    for j in range(len(path_d2_d5_full_multi_xred[i]['vtkOriginalPointIds'])-1):\n",
    "        cur_dist = threshed[0].geodesic_distance(path_d2_d5_full_multi_xred[i]['vtkOriginalPointIds'][0], path_d2_d5_full_multi_xred[i]['vtkOriginalPointIds'][j+1])\n",
    "        distance_d2_d5_all_multi_x[i].append(cur_dist)\n",
    "        \n",
    "    distance_d2_d5_all_multi_x_fin[i] = np.array(distance_d2_d5_all_multi_x[i])\n",
    "    \n",
    "#print(distance_d2_d5_all_multi_x)\n",
    "print(distance_d2_d5_all_multi_x_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot vertices along y-axis\n",
    "############################\n",
    "# deep qT1\n",
    "p4 = pv.Plotter()\n",
    "p4.add_mesh(mesh_qT1_dp, cmap=qT1_cmap, clim=[mean_dp-(4*sd_dp), mean_dp+(4*sd_dp)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_yd5)\n",
    "p4.add_mesh(test_yh)\n",
    "p4.add_mesh(test_yf)\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot reduced vertices and geodesic paths along y-axis\n",
    "######################################################\n",
    "# deep qT1\n",
    "i=0\n",
    "p4 = pv.Plotter()\n",
    "#p4.add_mesh(mesh_qT1_dp, cmap=qT1_cmap, clim=[mean_dp-(4*sd_dp), mean_dp+(4*sd_dp)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(mesh_f, cmap='RdPu')\n",
    "p4.add_mesh(test_yh_red, point_size=8, color='r')\n",
    "p4.add_mesh(test_yf_red,point_size=8, color='c')\n",
    "p4.add_mesh(test_yd5_red,point_size=8, color='y')\n",
    "#for i in range(len(path_f_h_full_multi_yred)):\n",
    "    #p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "    #p4.add_mesh(path_h_d2_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.show()\n",
    "\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(mesh_qT1_dp, cmap=qT1_cmap, clim=[mean_dp-(4*sd_dp), mean_dp+(4*sd_dp)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_yh_red, point_size=8, color='r')\n",
    "p4.add_mesh(test_yf_red,point_size=8, color='c')\n",
    "p4.add_mesh(test_yd5_red,point_size=8, color='y')\n",
    "#for i in range(len(path_f_h_full_multi_yred)):\n",
    "    #p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "    #p4.add_mesh(path_h_d2_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.screenshot(outdir+ind+'_multi_points_y_deep.png',transparent_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot reduced vertices and geodesic paths along y-axis\n",
    "######################################################\n",
    "# deep qT1\n",
    "i=0\n",
    "p4 = pv.Plotter()\n",
    "p4.add_mesh(mesh_qT1_dp, cmap=qT1_cmap, clim=[mean_dp-(4*sd_dp), mean_dp+(4*sd_dp)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_yh_red, point_size=8, color='r')\n",
    "p4.add_mesh(test_yf_red,point_size=8, color='c')\n",
    "p4.add_mesh(test_yd5_red,point_size=8, color='y')\n",
    "for i in range(len(path_f_h_full_multi_yred)):\n",
    "    p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "    p4.add_mesh(path_d2_d5_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.show()\n",
    "\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(mesh_qT1_dp, cmap=qT1_cmap, clim=[mean_dp-(4*sd_dp), mean_dp+(4*sd_dp)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_yh_red, point_size=8, color='r')\n",
    "p4.add_mesh(test_yf_red,point_size=8, color='c')\n",
    "p4.add_mesh(test_yd5_red,point_size=8, color='y')\n",
    "for i in range(len(path_f_h_full_multi_yred)):\n",
    "    p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "    p4.add_mesh(path_d2_d5_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.screenshot(outdir+ind+'_multi_paths_y_deep.png',transparent_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot vertices along x-axis\n",
    "############################\n",
    "# deep qT1\n",
    "p4 = pv.Plotter()\n",
    "p4.add_mesh(mesh_qT1_dp, cmap=qT1_cmap, clim=[mean_dp-(4*sd_dp), mean_dp+(4*sd_dp)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_xd5)\n",
    "p4.add_mesh(test_xh)\n",
    "p4.add_mesh(test_xf)\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot reduced vertices and geodesic paths along x-axis\n",
    "######################################################\n",
    "# deep qT1\n",
    "i=0\n",
    "p4 = pv.Plotter()\n",
    "#p4.add_mesh(mesh_qT1_dp, cmap=qT1_cmap, clim=[mean_dp-(4*sd_dp), mean_dp+(4*sd_dp)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(mesh_f, cmap='RdPu')\n",
    "p4.add_mesh(test_xh_red, point_size=8, color='r')\n",
    "p4.add_mesh(test_xf_red,point_size=8, color='c')\n",
    "p4.add_mesh(test_xd5_red,point_size=8, color='y')\n",
    "#for i in range(len(path_f_h_full_multi_yred)):\n",
    "#    p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.show()\n",
    "\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(mesh_qT1_dp, cmap=qT1_cmap, clim=[mean_dp-(3.5*sd_dp), mean_dp+(3.5*sd_dp)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_xh_red, point_size=8, color='r')\n",
    "p4.add_mesh(test_xf_red,point_size=8, color='c')\n",
    "p4.add_mesh(test_xd5_red,point_size=8, color='y')\n",
    "#for i in range(len(path_f_h_full_multi_yred)):\n",
    "#    p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.screenshot(outdir+ind+'_multi_points_x_deep.png',transparent_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot reduced vertices and geodesic paths along x-axis\n",
    "######################################################\n",
    "# deep qT1\n",
    "i=0\n",
    "p4 = pv.Plotter()\n",
    "p4.add_mesh(mesh_qT1_dp, cmap=qT1_cmap, clim=[mean_dp-(4*sd_dp), mean_dp+(4*sd_dp)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_xh_red, point_size=8, color='r')\n",
    "p4.add_mesh(test_xf_red,point_size=8, color='c')\n",
    "p4.add_mesh(test_xd5_red,point_size=8, color='y')\n",
    "for i in range(len(path_f_h_full_multi_xred)):\n",
    "    p4.add_mesh(path_f_h_full_multi_xred[i], line_width=4, color='k')\n",
    "    p4.add_mesh(path_d2_d5_full_multi_xred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.show()\n",
    "\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(mesh_qT1_dp, cmap=qT1_cmap, clim=[mean_dp-(4*sd_dp), mean_dp+(4*sd_dp)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_xh_red, point_size=8, color='r')\n",
    "p4.add_mesh(test_xf_red,point_size=8, color='c')\n",
    "p4.add_mesh(test_xd5_red,point_size=8, color='y')\n",
    "for i in range(len(path_f_h_full_multi_xred)):\n",
    "    p4.add_mesh(path_f_h_full_multi_xred[i], line_width=4, color='k')\n",
    "    p4.add_mesh(path_d2_d5_full_multi_xred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.screenshot(outdir+ind+'_multi_paths_x_deep.png',transparent_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot path\n",
    "# middle qT1\n",
    "mesh_qT1_im = pv.read(folder_qT1+filename_qT1_im)\n",
    "vtx_mesh_qT1_im = mesh_qT1_im['EmbedVertex']\n",
    "vtx_mesh_qT1_im_omitzero = vtx_mesh_qT1_im[np.nonzero(vtx_mesh_qT1_im)]\n",
    "mean_im = vtx_mesh_qT1_im_omitzero.mean()\n",
    "sd_im = vtx_mesh_qT1_im_omitzero.std()\n",
    "\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(path_d1_dist10, line_width=8, color='k')\n",
    "p4.add_mesh(path_d2_d5_full, line_width=8, color='k')\n",
    "p4.add_mesh(extracted_fd10, point_size=8, color='c')\n",
    "p4.add_mesh(extracted_d5, point_size=8, color='y')\n",
    "p4.add_mesh(extracted_h, point_size=8, color='r')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.show()\n",
    "\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(path_d1_dist10, line_width=8, color='k')\n",
    "p4.add_mesh(path_d2_d5_full, line_width=8, color='k')\n",
    "p4.add_mesh(extracted_fd10, point_size=8, color='c')\n",
    "p4.add_mesh(extracted_d5, point_size=8, color='y')\n",
    "p4.add_mesh(extracted_h, point_size=8, color='r')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.screenshot(outdir+ind+'_qT1_im_paths.png',transparent_background = True)\n",
    "#p4.savefig('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot reduced vertices and geodesic paths along y-axis\n",
    "######################################################\n",
    "# middle qT1\n",
    "i=0\n",
    "p4 = pv.Plotter()\n",
    "p4.add_mesh(mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_yh_red, point_size=6, color='r')\n",
    "p4.add_mesh(test_yf_red,point_size=6, color='c')\n",
    "p4.add_mesh(test_yd5_red,point_size=6, color='y')\n",
    "#for i in range(len(path_f_h_full_multi_yred)):\n",
    "    #p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "    #p4.add_mesh(path_h_d2_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.show()\n",
    "\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_yh_red, point_size=6, color='r')\n",
    "p4.add_mesh(test_yf_red,point_size=6, color='c')\n",
    "p4.add_mesh(test_yd5_red,point_size=6, color='y')\n",
    "#for i in range(len(path_f_h_full_multi_yred)):\n",
    "    #p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "    #p4.add_mesh(path_h_d2_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.screenshot(outdir+ind+'_multi_points_y_middle.png',transparent_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot reduced vertices and geodesic paths along x-axis\n",
    "######################################################\n",
    "# middle qT1\n",
    "i=0\n",
    "p4 = pv.Plotter()\n",
    "p4.add_mesh(mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_xh_red, point_size=6, color='r')\n",
    "p4.add_mesh(test_xf_red,point_size=6, color='c')\n",
    "p4.add_mesh(test_xd5_red,point_size=6, color='y')\n",
    "#for i in range(len(path_f_h_full_multi_yred)):\n",
    "#    p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.show()\n",
    "\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_xh_red, point_size=6, color='r')\n",
    "p4.add_mesh(test_xf_red,point_size=6, color='c')\n",
    "p4.add_mesh(test_xd5_red,point_size=6, color='y')\n",
    "#for i in range(len(path_f_h_full_multi_yred)):\n",
    "#    p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.screenshot(outdir+ind+'_multi_points_x_middle.png',transparent_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_d2_d1_d10_multi_y = []\n",
    "\n",
    "for j in range (len(path_f_h_full_multi_yred)):\n",
    "    path_d2_d1_d10_multi_y.append(np.concatenate((path_f_h_full_multi_yred[j]['vtkOriginalPointIds'],path_d2_d5_full_multi_yred[j]['vtkOriginalPointIds'][1:])))\n",
    "    print(path_f_h_full_multi_yred[j]['vtkOriginalPointIds'])\n",
    "print(path_d2_d1_d10_multi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract layer-specific qT1 along geodesic path\n",
    "#################################################\n",
    "qT1_dp_path_f_h_full = threshed[0]['qT1'][path_f_h_full['vtkOriginalPointIds']]\n",
    "qT1_dp_path_d2_d5_full = threshed[0]['qT1'][path_d2_d5_full['vtkOriginalPointIds']]\n",
    "print(qT1_dp_path_f_h_full)\n",
    "\n",
    "qT1_im_path_f_h_full = threshed[0]['middleqT1'][path_f_h_full['vtkOriginalPointIds']]\n",
    "qT1_im_path_d2_d5_full = threshed[0]['middleqT1'][path_d2_d5_full['vtkOriginalPointIds']]\n",
    "print(qT1_im_path_f_h_full)\n",
    "\n",
    "qT1_sim_path_f_h_full = threshed[0]['smoothmiddleqT1'][path_f_h_full['vtkOriginalPointIds']]\n",
    "qT1_sim_path_d2_d5_full = threshed[0]['smoothmiddleqT1'][path_d2_d5_full['vtkOriginalPointIds']]\n",
    "print(qT1_sim_path_f_h_full)\n",
    "\n",
    "# concatenate extracted qT1 values and geodesic distances from different geodesic paths\n",
    "#######################################################################################\n",
    "qT1_dp_path_d2_d1_d10 = np.concatenate((qT1_dp_path_f_h_full, qT1_dp_path_d2_d5_full))\n",
    "qT1_im_path_d2_d1_d10 = np.concatenate((qT1_im_path_f_h_full, qT1_im_path_d2_d5_full))\n",
    "qT1_sim_path_d2_d1_d10 = np.concatenate((qT1_sim_path_f_h_full, qT1_sim_path_d2_d5_full))\n",
    "distance_f_h_all_d2_d1_d10 = np.concatenate((distance_f_h_all_rev_d10,distance_d2_d5_all_fin))\n",
    "#print(qT1_im_path_d2_d1_d10)\n",
    "print(len(qT1_im_path_d2_d1_d10))\n",
    "print(len(qT1_im_path_f_h_full))\n",
    "print(len(distance_f_h_all_rev_d10))\n",
    "print(len(distance_f_h_all_d2_d1_d10))\n",
    "print(qT1_sim_path_d2_d1_d10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract layer-specific qT1 values from multiple paths along y-axis\n",
    "####################################################################\n",
    "i=0\n",
    "qT1_im_path_f_h_full_multi_y = []\n",
    "qT1_sim_path_f_h_full_multi_y = []\n",
    "\n",
    "qT1_im_path_h_d2_full_multi_y = []\n",
    "qT1_sim_path_h_d2_full_multi_y = []\n",
    "\n",
    "qT1_im_path_d2_d5_full_multi_y = []\n",
    "qT1_sim_path_d2_d5_full_multi_y = []\n",
    "\n",
    "for i in range(len(path_f_h_full_multi_yred)):\n",
    "    qT1_im_path_f_h_full_multi_y.append(threshed[0]['middleqT1'][path_f_h_full_multi_yred[i]['vtkOriginalPointIds']])\n",
    "    qT1_sim_path_f_h_full_multi_y.append(threshed[0]['smoothmiddleqT1'][path_f_h_full_multi_yred[i]['vtkOriginalPointIds']])\n",
    "       \n",
    "print(path_f_h_full_multi_yred)\n",
    "\n",
    "for i in range(len(path_d2_d5_full_multi_yred)):\n",
    "    qT1_im_path_d2_d5_full_multi_y.append(threshed[0]['middleqT1'][path_d2_d5_full_multi_yred[i]['vtkOriginalPointIds']])\n",
    "    qT1_sim_path_d2_d5_full_multi_y.append(threshed[0]['smoothmiddleqT1'][path_d2_d5_full_multi_yred[i]['vtkOriginalPointIds']])\n",
    "    \n",
    "    \n",
    "# extract layer-specific qT1 values from multiple paths along x-axis\n",
    "####################################################################\n",
    "i=0\n",
    "qT1_im_path_f_h_full_multi_x = []\n",
    "qT1_sim_path_f_h_full_multi_x = []\n",
    "\n",
    "qT1_im_path_h_d2_full_multi_x = []\n",
    "qT1_sim_path_h_d2_full_multi_x = []\n",
    "\n",
    "qT1_im_path_d2_d5_full_multi_x = []\n",
    "qT1_sim_path_d2_d5_full_multi_x = []\n",
    "\n",
    "for i in range(len(path_f_h_full_multi_xred)):\n",
    "    qT1_im_path_f_h_full_multi_x.append(threshed[0]['middleqT1'][path_f_h_full_multi_xred[i]['vtkOriginalPointIds']])\n",
    "    qT1_sim_path_f_h_full_multi_x.append(threshed[0]['smoothmiddleqT1'][path_f_h_full_multi_xred[i]['vtkOriginalPointIds']])\n",
    "    \n",
    "for i in range(len(path_d2_d5_full_multi_xred)):\n",
    "    qT1_im_path_d2_d5_full_multi_x.append(threshed[0]['middleqT1'][path_d2_d5_full_multi_xred[i]['vtkOriginalPointIds']])\n",
    "    qT1_sim_path_d2_d5_full_multi_x.append(threshed[0]['smoothmiddleqT1'][path_d2_d5_full_multi_xred[i]['vtkOriginalPointIds']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate extracted qT1 values and geodesic distances from different geodesic paths for all sampled paths along y-axis\n",
    "##########################################################################################################################\n",
    "j=0\n",
    "qT1_im_path_d2_d1_d10_multi_y = []\n",
    "qT1_sim_path_d2_d1_d10_multi_y = []\n",
    "distance_f_h_all_d2_d1_d10_multi_y = []\n",
    "\n",
    "for j in range (len(path_f_h_full_multi_yred)):\n",
    "    qT1_im_path_d2_d1_d10_multi_y.append(np.concatenate((qT1_im_path_f_h_full_multi_y[j], qT1_im_path_d2_d5_full_multi_y[j][1:])))\n",
    "    qT1_sim_path_d2_d1_d10_multi_y.append(np.concatenate((qT1_sim_path_f_h_full_multi_y[j], qT1_sim_path_d2_d5_full_multi_y[j][1:])))\n",
    "    distance_f_h_all_d2_d1_d10_multi_y.append(np.concatenate((distance_f_h_all_multi_y_rev[j],distance_d2_d5_all_multi_y_fin[j][1:])))\n",
    "\n",
    "print(qT1_im_path_d2_d1_d10_multi_y)\n",
    "print(distance_f_h_all_d2_d1_d10_multi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate extracted qT1 values and geodesic distances from different geodesic paths for all sampled paths along x-axis\n",
    "##########################################################################################################################\n",
    "j=0\n",
    "qT1_im_path_d2_d1_d10_multi_x = []\n",
    "qT1_sim_path_d2_d1_d10_multi_x = []\n",
    "distance_f_h_all_d2_d1_d10_multi_x = []\n",
    "\n",
    "for j in range (len(path_f_h_full_multi_xred)):\n",
    "    qT1_im_path_d2_d1_d10_multi_x.append(np.concatenate((qT1_im_path_f_h_full_multi_x[j], qT1_im_path_d2_d5_full_multi_x[j][1:])))\n",
    "    qT1_sim_path_d2_d1_d10_multi_x.append(np.concatenate((qT1_sim_path_f_h_full_multi_x[j], qT1_sim_path_d2_d5_full_multi_x[j][1:])))\n",
    "    distance_f_h_all_d2_d1_d10_multi_x.append(np.concatenate((distance_f_h_all_multi_x_rev[j], distance_d2_d5_all_multi_x_fin[j][1:])))\n",
    "\n",
    "print(qT1_im_path_d2_d1_d10_multi_x)\n",
    "print(distance_f_h_all_d2_d1_d10_multi_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D plots of multiple paths along y-axis\n",
    "#########################################\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "\n",
    "# set up a figure twice as wide as it is tall\n",
    "fig = plt.figure(figsize=plt.figaspect(8))\n",
    "\n",
    "# =============\n",
    "# Second subplot\n",
    "# =============\n",
    "# set up the axes for the first plot\n",
    "ax = fig.add_subplot(3, 1, 2, projection='3d', computed_zorder=False)\n",
    "\n",
    "i = 0\n",
    "\n",
    "yrange = [0,1,2,3,4]\n",
    "\n",
    "for k in reversed(yrange):\n",
    "    \n",
    "    yvalues = [k]*len(distance_f_h_all_d2_d1_d10_multi_y[k])\n",
    "    points = np.array([distance_f_h_all_d2_d1_d10_multi_y[k], yvalues, qT1_im_path_d2_d1_d10_multi_y[k]]).T.reshape(-1, 1, 3)\n",
    "    segments = np.concatenate([points[:-2],points[1:-1], points[2:]], axis=1)\n",
    "    \n",
    "    lc = Line3DCollection(segments, cmap='viridis')\n",
    "    # Set the values used for colormapping\n",
    "    lc.set_array(qT1_im_path_d2_d1_d10_multi_y[k])\n",
    "    lc.set_linewidth(4)\n",
    "    \n",
    "    ax.add_collection3d(lc)\n",
    "    ax.set_title('middle')\n",
    "    ax.set(zlabel='qT1 [ms]')\n",
    "    ax.set(xlabel='geodesic distance [mm]')\n",
    "    ax.set(ylabel='path number')\n",
    "    ax.set_ylim(min(yrange),max(yrange))\n",
    "    ax.set_zlim(2800,1200)\n",
    "    ax.set_zticks([2800,1200])\n",
    "    ax.set_yticks([0,4])\n",
    "    ax.set_xticks([min(distance_f_h_all_d2_d1_d10_multi_y[k]),0,max(distance_f_h_all_d2_d1_d10_multi_y[k])])\n",
    "    ax.set_xlim(min(distance_f_h_all_d2_d1_d10_multi_y[k]),max(distance_f_h_all_d2_d1_d10_multi_y[k]))\n",
    "    \n",
    "    ax.plot(distance_f_h_all_d2_d1_d10_multi_y[k][np.where(distance_f_h_all_d2_d1_d10_multi_y[k]==0)[0][0]], k, qT1_im_path_d2_d1_d10_multi_y[k][np.where(distance_f_h_all_d2_d1_d10_multi_y[k]==0)[0][0]], color='r', marker='.', markersize=12)\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plots\n",
    "############\n",
    "fig.savefig(outdir+ind+'_3D_multi_path_mulicolor_y.png')\n",
    "fig.savefig(outdir+ind+'_3D_multi_path_mulicolor_y.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D plots of multiple paths along x-axis\n",
    "#########################################\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from matplotlib.collections import PolyCollection\n",
    "\n",
    "# set up a figure twice as wide as it is tall\n",
    "fig = plt.figure(figsize=plt.figaspect(8))\n",
    "\n",
    "# =============\n",
    "# Second subplot\n",
    "# =============\n",
    "# set up the axes for the first plot\n",
    "ax = fig.add_subplot(3, 1, 2, projection='3d', computed_zorder=False)\n",
    "\n",
    "i = 0\n",
    "\n",
    "yrange = [0,1,2,3,4]\n",
    "\n",
    "for k in reversed(yrange):\n",
    "    \n",
    "    yvalues = [k]*len(distance_f_h_all_d2_d1_d10_multi_x[k])\n",
    "    points = np.array([distance_f_h_all_d2_d1_d10_multi_x[k], yvalues, qT1_im_path_d2_d1_d10_multi_x[k]]).T.reshape(-1, 1, 3)\n",
    "    segments = np.concatenate([points[:-2],points[1:-1], points[2:]], axis=1)\n",
    "    \n",
    "    lc = Line3DCollection(segments, cmap='viridis')\n",
    "    # Set the values used for colormapping\n",
    "    lc.set_array(qT1_im_path_d2_d1_d10_multi_x[k])\n",
    "    lc.set_linewidth(4)\n",
    "    \n",
    "    ax.add_collection3d(lc)\n",
    "    ax.set_title('middle')\n",
    "    ax.set(zlabel='qT1 [ms]')\n",
    "    ax.set(xlabel='geodesic distance [mm]')\n",
    "    ax.set(ylabel='path number')\n",
    "    ax.set_ylim(min(yrange),max(yrange))\n",
    "    ax.set_zlim(2800,1200)\n",
    "    ax.set_zticks([2800,1200])\n",
    "    ax.set_yticks(yrange)\n",
    "    ax.set_xticks([min(distance_f_h_all_d2_d1_d10_multi_x[k]),0,max(distance_f_h_all_d2_d1_d10_multi_x[k])])\n",
    "    ax.set_xlim(min(distance_f_h_all_d2_d1_d10_multi_x[k]),max(distance_f_h_all_d2_d1_d10_multi_x[k]))\n",
    "    \n",
    "    ax.plot(distance_f_h_all_d2_d1_d10_multi_x[k][np.where(distance_f_h_all_d2_d1_d10_multi_x[k]==0)[0][0]], k, qT1_im_path_d2_d1_d10_multi_x[k][np.where(distance_f_h_all_d2_d1_d10_multi_x[k]==0)[0][0]], color='r', marker='.', markersize=12)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plots\n",
    "############\n",
    "fig.savefig(outdir+ind+'_3D_multi_path_mulicolor_x.png')\n",
    "fig.savefig(outdir+ind+'_3D_multi_path_mulicolor_x.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publication-ready 3D plots of multiple paths for middle along x-axis\n",
    "######################################################################\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['axes.labelpad'] = 25\n",
    "\n",
    "# set up a figure twice as wide as it is tall\n",
    "fig = plt.figure(figsize=plt.figaspect(8))\n",
    "\n",
    "# =============\n",
    "# First subplot\n",
    "# =============\n",
    "# set up the axes for the first plot\n",
    "ax = fig.add_subplot(3, 1, 1, projection='3d', computed_zorder=False)\n",
    "\n",
    "i = 0\n",
    "\n",
    "yrange = [0,1,2,3,4]\n",
    "verts = []\n",
    "\n",
    "for k in yrange:\n",
    "    \n",
    "    yvalues = [k]*len(distance_f_h_all_d2_d1_d10_multi_x[k])\n",
    "    points = np.array([distance_f_h_all_d2_d1_d10_multi_x[k], yvalues, qT1_im_path_d2_d1_d10_multi_x[k]]).T.reshape(-1, 1, 3)\n",
    "    segments = np.concatenate([points[:-2],points[1:-1], points[2:]], axis=1)\n",
    "    \n",
    "    lc = Line3DCollection(segments, cmap='viridis')\n",
    "    # Set the values used for colormapping\n",
    "    lc.set_array(qT1_im_path_d2_d1_d10_multi_x[k])\n",
    "    lc.set_linewidth(4)\n",
    "    \n",
    "    ax.add_collection3d(lc)\n",
    "    #ax.set_title('middle')\n",
    "    #ax.set(zlabel='qT1 [ms]')\n",
    "    #ax.set(xlabel='geodesic distance\\n[mm]')\n",
    "    #ax.set(ylabel='path number')\n",
    "    ax.set_xlabel('geodesic distance [mm]\\ninferior > superior',labelpad=30, fontsize=20)\n",
    "    ax.set_ylabel('path number\\nanterior > posterior',labelpad=30, fontsize=20)\n",
    "    ax.set_zlabel('qT1\\n[ms]',labelpad=30, fontsize=20)\n",
    "    ax.tick_params(axis='both', labelsize=20,pad=5,width=25)\n",
    "    ax.tick_params(axis='z', labelsize=20,pad=15)\n",
    "    ax.set_ylim(max(yrange),min(yrange))\n",
    "    ax.set_zlim(2800,1200)\n",
    "    ax.set_zticks([2800,1200])\n",
    "    ax.set_yticks([4,0])\n",
    "    ax.set_xticks([round(min(distance_f_h_all_d2_d1_d10_multi_x[k])-0.5,1),0,round(max(distance_f_h_all_d2_d1_d10_multi_x[k])+0.5,1)])\n",
    "    ax.set_xlim(round(min(distance_f_h_all_d2_d1_d10_multi_x[k])-0.5,1),round(max(distance_f_h_all_d2_d1_d10_multi_x[k])+0.5,1))\n",
    "    \n",
    "    ax.plot(distance_f_h_all_d2_d1_d10_multi_x[k][np.where(distance_f_h_all_d2_d1_d10_multi_x[k]==0)[0][0]], k, qT1_im_path_d2_d1_d10_multi_x[k][np.where(distance_f_h_all_d2_d1_d10_multi_x[k]==0)[0][0]], color='r', marker='.', markersize=14)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plots\n",
    "############\n",
    "fig.savefig(outdir+ind+'_3D_multi_path_mulicolor_x_middle.png')\n",
    "fig.savefig(outdir+ind+'_3D_multi_path_mulicolor_x_middle.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publication-ready 3D plots of multiple paths for middle along y-axis\n",
    "######################################################################\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['axes.labelpad'] = 25\n",
    "\n",
    "# set up a figure twice as wide as it is tall\n",
    "fig = plt.figure(figsize=plt.figaspect(8))\n",
    "\n",
    "# =============\n",
    "# First subplot\n",
    "# =============\n",
    "# set up the axes for the first plot\n",
    "ax = fig.add_subplot(3, 1, 1, projection='3d', computed_zorder=False)\n",
    "\n",
    "i = 0\n",
    "\n",
    "yrange = [0,1,2,3,4]\n",
    "verts = []\n",
    "\n",
    "for k in reversed(yrange):\n",
    "    \n",
    "    yvalues = [k]*len(distance_f_h_all_d2_d1_d10_multi_y[k])\n",
    "    points = np.array([distance_f_h_all_d2_d1_d10_multi_y[k], yvalues, qT1_im_path_d2_d1_d10_multi_y[k]]).T.reshape(-1, 1, 3)\n",
    "    segments = np.concatenate([points[:-2],points[1:-1], points[2:]], axis=1)\n",
    "    \n",
    "    lc = Line3DCollection(segments, cmap='viridis')\n",
    "    # Set the values used for colormapping\n",
    "    lc.set_array(qT1_im_path_d2_d1_d10_multi_y[k])\n",
    "    lc.set_linewidth(4)\n",
    "    lc.set_clim(vmin=min(qT1_im_path_d2_d1_d10_multi_y[k]), vmax=max(qT1_im_path_d2_d1_d10_multi_y[k]))\n",
    "                \n",
    "    ax.add_collection3d(lc)\n",
    "    #ax.set_title('middle')\n",
    "    #ax.set(zlabel='qT1 [ms]')\n",
    "    #ax.set(xlabel='geodesic distance\\n[mm]')\n",
    "    #ax.set(ylabel='path number')\n",
    "    ax.set_xlabel('geodesic distance [mm]\\ninferior > superior',labelpad=30, fontsize=20)\n",
    "    ax.set_ylabel('path number\\nanterior > posterior',labelpad=30, fontsize=20)\n",
    "    ax.set_zlabel('qT1\\n[ms]',labelpad=30, fontsize=20)\n",
    "    ax.tick_params(axis='both', labelsize=20,pad=5,width=25)\n",
    "    ax.tick_params(axis='z', labelsize=20,pad=15)\n",
    "    ax.set_ylim(min(yrange),max(yrange))\n",
    "    ax.set_zlim(2800,1200)\n",
    "    ax.set_zticks([2800,1200])\n",
    "    ax.set_yticks([0,4])\n",
    "    ax.set_xticks([round(min(distance_f_h_all_d2_d1_d10_multi_y[k])-0.5,1),0,round(max(distance_f_h_all_d2_d1_d10_multi_y[k])+0.5,1)])\n",
    "    ax.set_xlim(round(min(distance_f_h_all_d2_d1_d10_multi_y[k])-0.5,1),round(max(distance_f_h_all_d2_d1_d10_multi_y[k])+0.5,1))\n",
    "    \n",
    "    ax.plot(distance_f_h_all_d2_d1_d10_multi_y[k][np.where(distance_f_h_all_d2_d1_d10_multi_y[k]==0)[0][0]], k, qT1_im_path_d2_d1_d10_multi_y[k][np.where(distance_f_h_all_d2_d1_d10_multi_y[k]==0)[0][0]], color='r', marker='.', markersize=14)\n",
    "#fig.colorbar(lc)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plots\n",
    "############\n",
    "fig.savefig(outdir+ind+'_3D_multi_path_mulicolor_y_middle.png')\n",
    "fig.savefig(outdir+ind+'_3D_multi_path_mulicolor_y_middle.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find most prominent peaks on geodesic paths sampled between forehead and little finger\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "\n",
    "yvalues = []\n",
    "peaks_m = [[0],[0],[0],[0],[0]]\n",
    "properties_m = [[0],[0],[0],[0],[0]]\n",
    "prominences = [[0],[0],[0],[0],[0]]\n",
    "prominences_prop = [[0],[0],[0],[0],[0]]\n",
    "max_prominences = [[0],[0],[0],[0],[0]]\n",
    "maxidx_prominences = [[0],[0],[0],[0],[0]]\n",
    "\n",
    "#peaks_m[k][maxidx_prominences[k]]\n",
    "\n",
    "rcParams['axes.labelpad'] = 25\n",
    "\n",
    "# set up a figure twice as wide as it is tall\n",
    "fig, axs = plt.subplots(5, 1, sharex=True)\n",
    "\n",
    "i = 0\n",
    "\n",
    "yrange = [0,1,2,3,4]\n",
    "\n",
    "for k in reversed(yrange):\n",
    "    print(k)\n",
    "    yvalues.append([k]*len(distance_f_h_all_d2_d1_d10_multi_y[k]))\n",
    "    peaks_m[k], properties_m[k] = find_peaks(qT1_im_path_d2_d1_d10_multi_y[k],prominence=2*np.std(qT1_im_path_d2_d1_d10_multi_y[k]),width=1)\n",
    "\n",
    "    axs[k ].plot(distance_f_h_all_d2_d1_d10_multi_y[k],qT1_im_path_d2_d1_d10_multi_y[k])\n",
    "    axs[k ].plot(distance_f_h_all_d2_d1_d10_multi_y[k][peaks_m[k]], qT1_im_path_d2_d1_d10_multi_y[k][peaks_m[k]], \"x\")\n",
    "    axs[k ].vlines(x = distance_f_h_all_d2_d1_d10_multi_y[k][peaks_m[k]], ymin = qT1_im_path_d2_d1_d10_multi_y[k][peaks_m[k]] - properties_m[k][\"prominences\"], ymax = qT1_im_path_d2_d1_d10_multi_y[k][peaks_m[k]], color = \"C1\")\n",
    "    #axs[4-k ].hlines(y = qT1_im_path_d2_d1_d10_multi_y[k][peaks_m[k]] - properties_m[k][\"prominences\"], xmin = distance_f_h_all_d2_d1_d10_multi_y[k][properties_m[k][\"left_bases\"]], xmax=distance_f_h_all_d2_d1_d10_multi_y[k][properties_m[k][\"right_bases\"]], color = \"C1\")\n",
    "    #axs[0 ].hlines(*results_full_m[1:], color=\"C3\")\n",
    "    axs[k ].plot(distance_f_h_all_d2_d1_d10_multi_y[k][0], qT1_im_path_d2_d1_d10_multi_y[k][0], color='c', marker='.', markersize=10)\n",
    "    axs[k ].plot(distance_f_h_all_d2_d1_d10_multi_y[k][-1], qT1_im_path_d2_d1_d10_multi_y[k][-1], color='y', marker='.', markersize=10)\n",
    "    axs[k ].plot(0, qT1_im_path_d2_d1_d10_multi_y[k][np.where(distance_f_h_all_d2_d1_d10_multi_y[k]==0)[0][0]], color='r', marker='.', markersize=10)\n",
    "    #axs[k ].plot(distance_f_h_all_d2_d1_d10_multi_y[k][len(qT1_im_path_f_h_full_multi_y[k])+len(qT1_im_path_h_d2_full_multi_y[k])-1], qT1_im_path_d2_d1_d10_multi_y[k][len(qT1_im_path_f_h_full_multi_y[k])+len(qT1_im_path_h_d2_full_multi_y[k])-1], color='m', marker='.', markersize=10)\n",
    "    axs[k ].invert_yaxis()\n",
    "    \n",
    "axs[k ].set_title('Middle Layer')\n",
    "    \n",
    "print(peaks_m)\n",
    "print(properties_m[k])\n",
    "print(properties_m[k][\"left_ips\"])\n",
    "print(distance_f_h_all_d2_d1_d10_multi_y[k][0])\n",
    "\n",
    "fig.tight_layout()\n",
    "#screenshot('/media/doehlerj/WIP-B1/Documents/FINAL/T1_profiles/S1_Paper/results/septa/DDlayers/'+ind+'_face_hand_gradient_myelin_smoothed_peak_prominence_multi_x_'+str(j)+'.png')\n",
    "fig.savefig(outdir+ind+'_face_hand_myelin_peaks_unsmoothed.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot reduced vertices and geodesic paths along y-axis\n",
    "######################################################\n",
    "# smoothed middle qT1\n",
    "i=0\n",
    "p4 = pv.Plotter()\n",
    "p4.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_yh_red, point_size=6, color='r')\n",
    "p4.add_mesh(test_yf_red,point_size=6, color='c')\n",
    "p4.add_mesh(test_yd5_red,point_size=6, color='y')\n",
    "#for i in range(len(path_f_h_full_multi_yred)):\n",
    "    #p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "    #p4.add_mesh(path_h_d2_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.show()\n",
    "\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_yh_red, point_size=6, color='r')\n",
    "p4.add_mesh(test_yf_red,point_size=6, color='c')\n",
    "p4.add_mesh(test_yd5_red,point_size=6, color='y')\n",
    "#for i in range(len(path_f_h_full_multi_yred)):\n",
    "    #p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "    #p4.add_mesh(path_h_d2_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.screenshot(outdir+ind+'_multi_points_y_middle_smooth.png',transparent_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance_f_h_all_d2_d1_d10_multi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot reduced vertices and geodesic paths along x-axis\n",
    "######################################################\n",
    "# smoothed middle qT1\n",
    "i=0\n",
    "p4 = pv.Plotter()\n",
    "p4.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_xh_red, point_size=6, color='r')\n",
    "p4.add_mesh(test_xf_red,point_size=6, color='c')\n",
    "p4.add_mesh(test_xd5_red,point_size=6, color='y')\n",
    "#for i in range(len(path_f_h_full_multi_yred)):\n",
    "    #p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "    #p4.add_mesh(path_h_d2_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.show()\n",
    "\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p4.add_mesh(test_xh_red, point_size=6, color='r')\n",
    "p4.add_mesh(test_xf_red,point_size=6, color='c')\n",
    "p4.add_mesh(test_xd5_red,point_size=6, color='y')\n",
    "#for i in range(len(path_f_h_full_multi_yred)):\n",
    "    #p4.add_mesh(path_f_h_full_multi_yred[i], line_width=4, color='k')\n",
    "    #p4.add_mesh(path_h_d2_full_multi_yred[i], line_width=4, color='k')\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.screenshot(outdir+ind+'_multi_points_x_middle_smooth.png',transparent_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publication-ready 3D plots of multiple paths for middle along y-axis\n",
    "######################################################################\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['axes.labelpad'] = 25\n",
    "\n",
    "# set up a figure twice as wide as it is tall\n",
    "fig = plt.figure(figsize=plt.figaspect(8))\n",
    "\n",
    "# =============\n",
    "# First subplot\n",
    "# =============\n",
    "# set up the axes for the first plot\n",
    "ax = fig.add_subplot(3, 1, 1, projection='3d', computed_zorder=False)\n",
    "\n",
    "i = 0\n",
    "\n",
    "yrange = [0,1,2,3,4]\n",
    "verts = []\n",
    "\n",
    "for k in reversed(yrange):\n",
    "    \n",
    "    yvalues = [k]*len(distance_f_h_all_d2_d1_d10_multi_y[k])\n",
    "    points = np.array([distance_f_h_all_d2_d1_d10_multi_y[k], yvalues, qT1_sim_path_d2_d1_d10_multi_y[k]]).T.reshape(-1, 1, 3)\n",
    "    segments = np.concatenate([points[:-2],points[1:-1], points[2:]], axis=1)\n",
    "    \n",
    "    lc = Line3DCollection(segments, cmap='viridis')\n",
    "    # Set the values used for colormapping\n",
    "    lc.set_array(qT1_sim_path_d2_d1_d10_multi_y[k])\n",
    "    lc.set_linewidth(4)\n",
    "    lc.set_clim(vmin=min(qT1_sim_path_d2_d1_d10_multi_y[k]), vmax=max(qT1_sim_path_d2_d1_d10_multi_y[k]))\n",
    "                \n",
    "    ax.add_collection3d(lc)\n",
    "    #ax.set_title('middle')\n",
    "    #ax.set(zlabel='qT1 [ms]')\n",
    "    #ax.set(xlabel='geodesic distance\\n[mm]')\n",
    "    #ax.set(ylabel='path number')\n",
    "    ax.set_xlabel('geodesic distance [mm]\\ninferior > superior',labelpad=30, fontsize=20)\n",
    "    ax.set_ylabel('path number\\nanterior > posterior',labelpad=30, fontsize=20)\n",
    "    ax.set_zlabel('qT1\\n[ms]',labelpad=30, fontsize=20)\n",
    "    ax.tick_params(axis='both', labelsize=20,pad=5,width=25)\n",
    "    ax.tick_params(axis='z', labelsize=20,pad=15)\n",
    "    ax.set_ylim(min(yrange),max(yrange))\n",
    "    ax.set_zlim(2800,1200)\n",
    "    ax.set_zticks([2800,1200])\n",
    "    ax.set_yticks([0,4])\n",
    "    ax.set_xticks([round(min(distance_f_h_all_d2_d1_d10_multi_y[k])-0.5,1),0,round(max(distance_f_h_all_d2_d1_d10_multi_y[k])+0.5,1)])\n",
    "    ax.set_xlim(round(min(distance_f_h_all_d2_d1_d10_multi_y[k])-0.5,1),round(max(distance_f_h_all_d2_d1_d10_multi_y[k])+0.5,1))\n",
    "    \n",
    "    ax.plot(0, k, qT1_sim_path_d2_d1_d10_multi_y[k][np.where(distance_f_h_all_d2_d1_d10_multi_y[k]==0)[0][0]], color='r', marker='.', markersize=14)\n",
    "#fig.colorbar(lc)\n",
    "fig.tight_layout()\n",
    "\n",
    "# save plots\n",
    "############\n",
    "fig.savefig(outdir+ind+'_3D_multi_path_mulicolor_y_middle_smooth2.png')\n",
    "fig.savefig(outdir+ind+'_3D_multi_path_mulicolor_y_middle_smooth2.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publication-ready 3D plots of multiple paths for middle along x-axis\n",
    "######################################################################\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['axes.labelpad'] = 25\n",
    "\n",
    "# set up a figure twice as wide as it is tall\n",
    "fig = plt.figure(figsize=plt.figaspect(8))\n",
    "\n",
    "# =============\n",
    "# First subplot\n",
    "# =============\n",
    "# set up the axes for the first plot\n",
    "ax = fig.add_subplot(3, 1, 1, projection='3d', computed_zorder=False)\n",
    "\n",
    "i = 0\n",
    "\n",
    "yrange = [0,1,2,3,4]\n",
    "verts = []\n",
    "\n",
    "for k in reversed(yrange):\n",
    "    \n",
    "    yvalues = [k]*len(distance_f_h_all_d2_d1_d10_multi_x[k])\n",
    "    points = np.array([distance_f_h_all_d2_d1_d10_multi_x[k], yvalues, qT1_sim_path_d2_d1_d10_multi_x[k]]).T.reshape(-1, 1, 3)\n",
    "    segments = np.concatenate([points[:-2],points[1:-1], points[2:]], axis=1)\n",
    "    \n",
    "    lc = Line3DCollection(segments, cmap='viridis')\n",
    "    # Set the values used for colormapping\n",
    "    lc.set_array(qT1_sim_path_d2_d1_d10_multi_x[k])\n",
    "    lc.set_linewidth(4)\n",
    "    lc.set_clim(vmin=min(qT1_sim_path_d2_d1_d10_multi_x[k]), vmax=max(qT1_sim_path_d2_d1_d10_multi_x[k]))\n",
    "                \n",
    "    ax.add_collection3d(lc)\n",
    "    #ax.set_title('middle')\n",
    "    #ax.set(zlabel='qT1 [ms]')\n",
    "    #ax.set(xlabel='geodesic distance\\n[mm]')\n",
    "    #ax.set(ylabel='path number')\n",
    "    ax.set_xlabel('geodesic distance [mm]\\ninferior > superior',labelpad=30, fontsize=20)\n",
    "    ax.set_ylabel('path number\\nanterior > posterior',labelpad=30, fontsize=20)\n",
    "    ax.set_zlabel('qT1\\n[ms]',labelpad=30, fontsize=20)\n",
    "    ax.tick_params(axis='both', labelsize=20,pad=5,width=25)\n",
    "    ax.tick_params(axis='z', labelsize=20,pad=15)\n",
    "    ax.set_ylim(min(yrange),max(yrange))\n",
    "    ax.set_zlim(2800,1200)\n",
    "    ax.set_zticks([2800,1200])\n",
    "    ax.set_yticks([0,4])\n",
    "    ax.set_xticks([round(min(distance_f_h_all_d2_d1_d10_multi_x[k])-0.5,1),0,round(max(distance_f_h_all_d2_d1_d10_multi_x[k])+0.5,1)])\n",
    "    ax.set_xlim(round(min(distance_f_h_all_d2_d1_d10_multi_x[k])-0.5,1),round(max(distance_f_h_all_d2_d1_d10_multi_x[k])+0.5,1))\n",
    "    \n",
    "    ax.plot(0, k, qT1_sim_path_d2_d1_d10_multi_x[k][np.where(distance_f_h_all_d2_d1_d10_multi_x[k]==0)[0][0]], color='r', marker='.', markersize=14)\n",
    "#fig.colorbar(lc)\n",
    "fig.tight_layout()\n",
    "\n",
    "# save plots\n",
    "############\n",
    "fig.savefig(outdir+ind+'_3D_multi_path_mulicolor_x_middle_smooth.png')\n",
    "fig.savefig(outdir+ind+'_3D_multi_path_mulicolor_x_middle_smooth.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find most prominent peaks on geodesic paths sampled between forehead and little finger\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "\n",
    "peaks_m = [[0],[0],[0],[0],[0]]\n",
    "properties_m = [[0],[0],[0],[0],[0]]\n",
    "\n",
    "rcParams['axes.labelpad'] = 25\n",
    "\n",
    "# set up a figure twice as wide as it is tall\n",
    "fig, axs = plt.subplots(5, 1, sharex=True)\n",
    "\n",
    "i = 0\n",
    "yrange = [0,1,2,3,4]\n",
    "\n",
    "# plot data\n",
    "for k in reversed(yrange):\n",
    "    print(k)\n",
    "    print(np.std(qT1_sim_path_d2_d1_d10_multi_y[k]))\n",
    "    peaks_m[k], properties_m[k] = find_peaks(qT1_sim_path_d2_d1_d10_multi_y[k],prominence=2*np.std(qT1_sim_path_d2_d1_d10_multi_y[k]),width=1,height=0,plateau_size=0,threshold=0)\n",
    "\n",
    "    axs[k ].plot(distance_f_h_all_d2_d1_d10_multi_y[k],qT1_sim_path_d2_d1_d10_multi_y[k])\n",
    "    axs[k ].plot(distance_f_h_all_d2_d1_d10_multi_y[k][peaks_m[k]], qT1_sim_path_d2_d1_d10_multi_y[k][peaks_m[k]], \"x\")\n",
    "    axs[k ].vlines(x = distance_f_h_all_d2_d1_d10_multi_y[k][peaks_m[k]], ymin = qT1_sim_path_d2_d1_d10_multi_y[k][peaks_m[k]] - properties_m[k][\"prominences\"], ymax = qT1_sim_path_d2_d1_d10_multi_y[k][peaks_m[k]], color = \"C1\")\n",
    "\n",
    "    axs[k ].plot(distance_f_h_all_d2_d1_d10_multi_y[k][0], qT1_sim_path_d2_d1_d10_multi_y[k][0], color='c', marker='.', markersize=10)\n",
    "    axs[k ].plot(distance_f_h_all_d2_d1_d10_multi_y[k][-1], qT1_sim_path_d2_d1_d10_multi_y[k][-1], color='y', marker='.', markersize=10)\n",
    "    axs[k ].plot(0, qT1_sim_path_d2_d1_d10_multi_y[k][np.where(distance_f_h_all_d2_d1_d10_multi_y[k]==0)[0][0]], color='r', marker='.', markersize=10)\n",
    "    #axs[k ].plot(distance_f_h_all_d2_d1_d10_multi_y[k][len(qT1_sim_path_f_h_full_multi_y[k])+len(qT1_sim_path_h_d2_full_multi_y[k])-1], qT1_sim_path_d2_d1_d10_multi_y[k][len(qT1_sim_path_f_h_full_multi_y[k])+len(qT1_sim_path_h_d2_full_multi_y[k])-1], color='m', marker='.', markersize=10)\n",
    "    axs[k ].invert_yaxis()\n",
    "    \n",
    "axs[k ].set_title('Middle Layer')\n",
    "\n",
    "fig.savefig(outdir+ind+'_myelin_peaks_middle_smoothed.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot detrended qT1 values against normalized geodesic distances in one subplot \n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from scipy.signal import find_peaks, peak_prominences, detrend, normalize\n",
    "\n",
    "rcParams['axes.labelpad'] = 25\n",
    "\n",
    "fig, axs = plt.subplots(sharex=True)\n",
    "\n",
    "i = 0\n",
    "\n",
    "yrange = [0,1,2,3,4]\n",
    "\n",
    "detrended_signal = []\n",
    "\n",
    "for k in reversed(yrange):\n",
    "    normalizedData = (distance_f_h_all_d2_d1_d10_multi_y[k]-np.min(distance_f_h_all_d2_d1_d10_multi_y[k]))/(np.max(distance_f_h_all_d2_d1_d10_multi_y[k])-np.min(distance_f_h_all_d2_d1_d10_multi_y[k]))\n",
    "    axs.plot(normalizedData,detrend(qT1_sim_path_d2_d1_d10_multi_y[k]))\n",
    "    axs.invert_yaxis()\n",
    "\n",
    "axs.set_title('Middle Layer')\n",
    "\n",
    "fig.savefig(outdir+ind+'_detrended_myelin_peaks_middle_norm_geod_smoothed.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qT1_sim_path_d2_d1_d10_multi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance_f_h_all_d2_d1_d10_multi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detrend_signal(signal):\n",
    "    detrended_signal = []\n",
    "\n",
    "    for k in range(len(signal)):\n",
    "        detrended_signal.append(detrend(signal[k]))\n",
    "\n",
    "    print(\"Detrended Signal: \", detrended_signal)\n",
    "    return detrended_signal\n",
    "\n",
    "detrended_signal = detrend_signal(qT1_sim_path_d2_d1_d10_multi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot detrended qT1 signal and detected peaks against normalized geodesic distances\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from scipy.signal import find_peaks, peak_prominences, detrend, normalize\n",
    "\n",
    "yvalues = []\n",
    "peaks_m = [[0],[0],[0],[0],[0]]\n",
    "properties_m = [[0],[0],[0],[0],[0]]\n",
    "\n",
    "#peaks_m[k][maxidx_prominences[k]]\n",
    "\n",
    "rcParams['axes.labelpad'] = 25\n",
    "\n",
    "# set up a figure twice as wide as it is tall\n",
    "fig, axs = plt.subplots(5, 1, sharex=True)\n",
    "\n",
    "i = 0\n",
    "\n",
    "yrange = [0,1,2,3,4]\n",
    "verts = []\n",
    "\n",
    "# plot data\n",
    "for k in reversed(yrange):\n",
    "    \n",
    "    # normalize geodesic distances to detect nearest peaks on neighboring paths  \n",
    "    normalizedData = (distance_f_h_all_d2_d1_d10_multi_y[k]-np.min(distance_f_h_all_d2_d1_d10_multi_y[k]))/(np.max(distance_f_h_all_d2_d1_d10_multi_y[k])-np.min(distance_f_h_all_d2_d1_d10_multi_y[k]))\n",
    "    \n",
    "    peaks_m[k], properties_m[k] = find_peaks(detrended_signal[k],prominence=2*np.std(abs(detrended_signal[k])),width=1,height=0,plateau_size=0,threshold=0)\n",
    "    zeropoint = np.where(distance_f_h_all_d2_d1_d10_multi_y[k]==0)[0][0]\n",
    "  \n",
    "    axs[k ].plot(normalizedData,detrended_signal[k])\n",
    "    axs[k ].plot(normalizedData[peaks_m[k]], detrended_signal[k][peaks_m[k]], \"x\")\n",
    "    axs[k ].vlines(x =  normalizedData[peaks_m[k]], ymin = detrended_signal[k][peaks_m[k]] - properties_m[k][\"prominences\"], ymax = detrended_signal[k][peaks_m[k]], color = \"C1\")\n",
    "\n",
    "    axs[k ].plot(normalizedData[0], detrended_signal[k][0], color='c', marker='.', markersize=10)\n",
    "    axs[k ].plot(normalizedData[-1], detrended_signal[k][-1], color='y', marker='.', markersize=10)\n",
    "    axs[k ].plot(normalizedData[zeropoint], detrended_signal[k][np.where(distance_f_h_all_d2_d1_d10_multi_y[k]==0)[0][0]], color='r', marker='.', markersize=10)\n",
    "    #axs[k ].plot(distance_f_h_all_d2_d1_d10_multi_y[k][len(qT1_sim_path_f_h_full_multi_y[k])+len(qT1_sim_path_h_d2_full_multi_y[k])-1], detrended_signal[k][len(qT1_sim_path_f_h_full_multi_y[k])+len(qT1_sim_path_h_d2_full_multi_y[k])-1], color='m', marker='.', markersize=10)\n",
    "    axs[k ].invert_yaxis()\n",
    "    \n",
    "axs[k ].set_title('Middle Layer')\n",
    "\n",
    "fig.savefig(outdir+ind+'_detrended_myelin_peaks_middle_smoothed_norm.png')  \n",
    "\n",
    "# set up a figure twice as wide as it is tall\n",
    "fig, axs = plt.subplots(5, 1, sharex=True)\n",
    "\n",
    "i = 0\n",
    "\n",
    "yrange = [0,1,2,3,4]\n",
    "verts = []\n",
    "\n",
    "# plot data\n",
    "for k in reversed(yrange):\n",
    "    \n",
    "    # normalize geodesic distances to detect nearest peaks on neighboring paths  \n",
    "    normalizedData = distance_f_h_all_d2_d1_d10_multi_y[k]\n",
    "    \n",
    "    peaks_m[k], properties_m[k] = find_peaks(detrended_signal[k],prominence=2*np.std(abs(detrended_signal[k])),width=1,height=0,plateau_size=0,threshold=0)\n",
    "    zeropoint = np.where(distance_f_h_all_d2_d1_d10_multi_y[k]==0)[0][0]\n",
    "  \n",
    "    axs[k ].plot(normalizedData,detrended_signal[k])\n",
    "    axs[k ].plot(normalizedData[peaks_m[k]], detrended_signal[k][peaks_m[k]], \"x\")\n",
    "    axs[k ].vlines(x =  normalizedData[peaks_m[k]], ymin = detrended_signal[k][peaks_m[k]] - properties_m[k][\"prominences\"], ymax = detrended_signal[k][peaks_m[k]], color = \"C1\")\n",
    "\n",
    "    axs[k ].plot(normalizedData[0], detrended_signal[k][0], color='c', marker='.', markersize=10)\n",
    "    axs[k ].plot(normalizedData[-1], detrended_signal[k][-1], color='y', marker='.', markersize=10)\n",
    "    axs[k ].plot(normalizedData[zeropoint], detrended_signal[k][np.where(distance_f_h_all_d2_d1_d10_multi_y[k]==0)[0][0]], color='r', marker='.', markersize=10)\n",
    "    #axs[k ].plot(distance_f_h_all_d2_d1_d10_multi_y[k][len(qT1_sim_path_f_h_full_multi_y[k])+len(qT1_sim_path_h_d2_full_multi_y[k])-1], detrended_signal[k][len(qT1_sim_path_f_h_full_multi_y[k])+len(qT1_sim_path_h_d2_full_multi_y[k])-1], color='m', marker='.', markersize=10)\n",
    "    axs[k ].invert_yaxis()\n",
    "    \n",
    "axs[k ].set_title('Middle Layer')\n",
    "\n",
    "fig.savefig(outdir+ind+'_detrended_myelin_peaks_middle_smoothed.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance_f_h_all_d2_d1_d10_multi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = distance_f_h_all_d2_d1_d10_multi_y\n",
    "\n",
    "def normalize_data(signals):\n",
    "    \n",
    "    normalizedData = [[] for i in list(range(0,len(signals)))]\n",
    "    signal_tmp = [[] for i in list(range(0,len(signals)))]\n",
    "    \n",
    "    for k in range(0,len(signals)):\n",
    "        # normalize geodesic distances to detect nearest peaks on neighboring paths  \n",
    "        #normalizedData[k] = (signals[k]-np.min(signals[k]))/(np.max(signals[k])-np.min(signals[k]))\n",
    "        normalizedData[k] = signals[k]\n",
    "        normalizedData[k] = normalizedData[k].tolist()\n",
    "    \n",
    "    tmpi = signals\n",
    "    \n",
    "    print(normalizedData)\n",
    "        \n",
    "    minval = min(min(normalizedData))\n",
    "    print(minval)\n",
    "    \n",
    "    for signal in range(0,len(tmpi)):\n",
    "        res = [x + abs(minval) for x in tmpi[signal]]\n",
    "        signal_tmp[signal] = res\n",
    "    \n",
    "    Data_type = object\n",
    "    \n",
    "    #make distances positive\n",
    "    normalizedDataf = np.array(signal_tmp, dtype=Data_type)\n",
    "    \n",
    "    print(normalizedDataf)\n",
    "    return normalizedDataf\n",
    "\n",
    "normalizedData = normalize_data(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance_f_h_all_d2_d1_d10_multi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import sem\n",
    "from peakutils import indexes\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "from itertools import combinations\n",
    "\n",
    "from scipy.stats import chi2\n",
    "from matplotlib import patches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def define_comparisons(signals,peaks_m):\n",
    "    \n",
    "    signal_numbers = list(range(0,len(signals)))\n",
    "    print(signal_numbers)\n",
    "    \n",
    "    #signal_pairs = list(combinations(signal_numbers, 2))\n",
    "    #signal_pairs = list([[signals[0],signals[1]],[signals[1],signals[2]],[signals[2],signals[3]],[signals[3],signals[4]],[signals[0],signals[2]],[signals[1],signals[3]],[signals[2],signals[4]]])\n",
    "    signal_pairs = list([[0,1],[1,2],[2,3],[3,4],[0,2],[1,3],[2,4]])\n",
    "    print(signal_pairs)\n",
    "    \n",
    "    print(len(signals))\n",
    "    \n",
    "    #signal_pairs = [i for i in signal_pairs if i != (0,len(signals)-1)]\n",
    "    #print(signal_pairs)\n",
    "    \n",
    "    peak_idx_pairs = [[] for i in list(range(0,len(signal_pairs)))]\n",
    "    print(peak_idx_pairs)\n",
    "    \n",
    "    print(\"Peaks_m: \")\n",
    "    print(peaks_m[0])\n",
    "    \n",
    "    #iterate over each signal and sort peaks according to signal pairs\n",
    "    for i in range(0,len(signals)):      \n",
    "        print(list(peaks_m[0][i]))\n",
    "        peak = list(peaks_m[0][i])\n",
    "        \n",
    "        for k in range(0,len(signal_pairs)):\n",
    "            if signal_pairs[k][0] == i or signal_pairs[k][1] == i:\n",
    "                peak_idx_pairs[k].append(peak)\n",
    "    \n",
    "    print(\"Peak_idx_pairs: \")\n",
    "    print(peak_idx_pairs)\n",
    "    \n",
    "    return peak_idx_pairs, signal_pairs\n",
    "\n",
    "def find_prominent_peaks(signals): #find peaks in original signal, project peaks to DTW space and calculate intersections\n",
    "\n",
    "    peaks_m = [[0]]*len(signals)\n",
    "    properties_m = [[0]]*len(signals)\n",
    "    \n",
    "    for i in range(len(signals)):\n",
    "        peaks_m[i], properties_m[i] = find_peaks(signals[i],prominence=2*np.std(abs(signals[i])),width=1,height=0,plateau_size=0,threshold=0)\n",
    "\n",
    "    return peaks_m, properties_m\n",
    "\n",
    "\n",
    "def get_border_params(combined_final_borders,peaks_m,signals,orig_signals):    \n",
    "    \n",
    "    border_loc = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "    path_id = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "    borderp = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "    borderh = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "    borderw = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "    borderintens = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "    borderorigintens = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "    borderqsm = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "    borderaqsm = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "    borderpqsm = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "    bordernqsm = np.empty((5,5,)) * np.nan # 5 paths x 5 borders    \n",
    "\n",
    "    borderf = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "    borderh = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "    \n",
    "    #extract border parameters\n",
    "    count = 0\n",
    "    vcount = 0\n",
    "    for border in combined_final_borders: #loop over all detected borders\n",
    "        vcount = 0\n",
    "        for valley in border: #for each border loop over all detected valleys that shape this specific border\n",
    "            border_loc[count][vcount] = valley[1]\n",
    "            path_id[count][vcount] = valley[0]\n",
    "            borderp[count][vcount] = peaks_m[1][valley[0]][\"prominences\"][np.where(peaks_m[0][valley[0]]==valley[1])[0]]\n",
    "            borderh[count][vcount] = peaks_m[1][valley[0]][\"peak_heights\"][np.where(peaks_m[0][valley[0]]==valley[1])[0]]\n",
    "            borderw[count][vcount] = peaks_m[1][valley[0]][\"widths\"][np.where(peaks_m[0][valley[0]]==valley[1])[0]]\n",
    "            borderintens[count][vcount] = signals[valley[0]][valley[1]]\n",
    "            borderorigintens[count][vcount] = orig_signals[valley[0]][valley[1]]\n",
    "            vcount = vcount + 1\n",
    "        count = count + 1\n",
    "    \n",
    "    border_loc = border_loc.transpose()\n",
    "    path_id = path_id.transpose()\n",
    "    borderp = borderp.transpose()\n",
    "    borderh = borderh.transpose()\n",
    "    borderw = borderw.transpose()\n",
    "    borderintens = borderintens.transpose()\n",
    "    borderorigintens = borderorigintens.transpose()\n",
    "    borderqsm = borderqsm.transpose()\n",
    "    borderaqsm = borderaqsm.transpose()\n",
    "    borderpqsm = borderpqsm.transpose()\n",
    "    bordernqsm = bordernqsm.transpose()\n",
    "\n",
    "    borderf = borderf.transpose()\n",
    "    borderh = borderh.transpose()\n",
    "    \n",
    "    np.savetxt(outdir+ind+\"_border_locations_middle_multi_y_paths.csv\", border_loc, delimiter=\" \")\n",
    "    np.savetxt(outdir+ind+\"_path_id_middle_multi_y_paths.csv\", path_id, delimiter=\" \")\n",
    "    np.savetxt(outdir+ind+\"_border_prominences_middle_multi_y_paths.csv\", borderp, delimiter=\" \")\n",
    "    np.savetxt(outdir+ind+\"_border_widths_middle_multi_y_paths.csv\", borderw, delimiter=\" \")\n",
    "    np.savetxt(outdir+ind+\"_border_heights_middle_multi_y_paths.csv\", borderh, delimiter=\" \")\n",
    "    np.savetxt(outdir+ind+\"_border_intensity_middle_multi_y_paths.csv\", borderintens, delimiter=\" \")\n",
    "    np.savetxt(outdir+ind+\"_border_origintensity_middle_multi_y_paths.csv\", borderorigintens, delimiter=\" \")\n",
    "\n",
    "    combined_border_params = np.concatenate((path_id, border_loc, borderw, borderh, borderp, borderintens, borderorigintens, borderqsm, borderaqsm, borderpqsm, bordernqsm, borderf, borderh), axis=1)\n",
    "    print(combined_border_params)\n",
    "\n",
    "    np.savetxt(outdir+ind+\"_border_params_singlepaths_middle_multi_y_paths.csv\", combined_border_params, delimiter=\" \")\n",
    "\n",
    "    mean_combined_border_params = np.nanmean(combined_border_params,axis=0)\n",
    "    print(mean_combined_border_params)\n",
    "    \n",
    "    border_count = len(combined_final_borders)\n",
    "    \n",
    "    final_mean_combined_border_params = np.insert(mean_combined_border_params,0,border_count)\n",
    "    final_mean_combined_border_params = np.insert(final_mean_combined_border_params,0,ind_i)\n",
    "    print(final_mean_combined_border_params)\n",
    "\n",
    "    # create column headers for table and save header file\n",
    "    header = np.array([['ID','border_count','path1','path2','path3','path4','path5','borderloc1','borderloc2','borderloc3','borderloc4','borderloc5','width1','width2','width3','width4','width5','height1','height2','height3','height4','height5','prom1','prom2','prom3','prom4','prom5','intens1','intens2','intens3','intens4','intens5','origintens1','origintens2','origintens3','origintens4','origintens5','borderqsm1','borderqsm2','borderqsm3','borderqsm4','borderqsm5','borderaqsm1','borderaqsm2','borderaqsm3','borderaqsm4','borderaqsm5','borderpqsm1','borderpqsm2','borderpqsm3','borderpqsm4','borderpqsm5','bordernqsm1','bordernqsm2','bordernqsm3','bordernqsm4','bordernqsm5','borderspmTf1','borderspmTh1','borderspmTf2','borderspmTh2','borderspmTf3','borderspmTh3','borderspmTf4','borderspmTh4','borderspmTf5','borderspmTh5']])\n",
    "    print(header[0])\n",
    "    np.savetxt(outdir+ind+\"_border_header_middle_multi_y_paths.csv\", header, delimiter=\" \", fmt=\"%s\")\n",
    "\n",
    "    header_str = \"ID,border_count,path1,path2,path3,path4,path5,borderloc1,borderloc2,borderloc3,borderloc4,borderloc5,width1,width2,width3,width4,width5,height1,height2,height3,height4,height5,prom1,prom2,prom3,prom4,prom5,intens1,intens2,intens3,intens4,intens5,origintens1,origintens2,origintens3,origintens4,origintens5,borderqsm1,borderqsm2,borderqsm3,borderqsm4,borderqsm5,borderaqsm1,borderaqsm2,borderaqsm3,borderaqsm4,borderaqsm5,borderpqsm1,borderpqsm2,borderpqsm3,borderpqsm4,borderpqsm5,bordernqsm1,bordernqsm2,bordernqsm3,bordernqsm4,bordernqsm5,borderspmTf1,borderspmTh1,borderspmTf2,borderspmTh2,borderspmTf3,borderspmTh3,borderspmTf4,borderspmTh4,borderspmTf5,borderspmTh5\"\n",
    "\n",
    "    # save border parameter values (from anterior to posterior)\n",
    "    # includes: number of detected borders, single widths, single heights, single prominences, single plateau sizes, single left thresholds, single right thresholds, single border width heights\n",
    "    border_params = np.array([final_mean_combined_border_params])\n",
    "    print(border_params)\n",
    "    np.savetxt(outdir+ind+\"_border_params_mean_middle_multi_y_paths.csv\", border_params, delimiter=\" \")\n",
    "    np.savetxt(outdir+ind+\"_border_params_header_middle_multi_y_paths.csv\", border_params, header=header_str, delimiter=\" \")\n",
    "\n",
    "    border_params_allsubj = np.genfromtxt(outdir_all+\"allsubj_border_params_middle_multi_y_paths.csv\",delimiter=\",\")\n",
    "    print(border_params_allsubj)\n",
    "    border_params_allsubj[ind_i] = border_params\n",
    "    print(border_params_allsubj[ind_i])\n",
    "    print(ind_i)\n",
    "\n",
    "    np.savetxt(outdir_all+\"allsubj_border_params_middle_multi_y_paths.csv\", border_params_allsubj, delimiter=\",\")   \n",
    "    \n",
    "    return border_params,header\n",
    "\n",
    "def plot_signals(peaks_m_unq,signals,xdata,fhpath,d2path,datatype,peaks_m):\n",
    "\n",
    "    colors = [\"darkorange\",\"darkcyan\",\"darkviolet\",\"darkred\",\"darkgreen\",\"darkblue\"]\n",
    "    \n",
    "    if len(signals) > 1:\n",
    "        fig, axs = plt.subplots(len(signals), 1, sharex=True)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(len(signals)+1, 1, sharex=True)\n",
    "        \n",
    "    for k in range(len(signals)):\n",
    "        # plot qT1 signal against geodesic distances\n",
    "        axs[k ].plot(xdata[k],signals[k])\n",
    "        axs[k ].invert_yaxis()\n",
    "        \n",
    "        peak_color = 0\n",
    "        \n",
    "        for peaks in peaks_m_unq: \n",
    "            \n",
    "            for peak in peaks:\n",
    "                if peak[0] == k:\n",
    "                    axs[k ].plot(xdata[peak[0]][peak[1]],signals[peak[0]][peak[1]],marker=\"x\",markeredgewidth=2,color=colors[peak_color])\n",
    "            peak_color = peak_color + 1\n",
    "    \n",
    "    fig.savefig(outdir+ind+'_'+datatype+'_qT1_signals_final_peaks.png')\n",
    "    \n",
    "    \n",
    "    if len(signals) > 1:\n",
    "        fig, axs = plt.subplots(len(signals), 1, sharex=True)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(len(signals)+1, 1, sharex=True)\n",
    "\n",
    "    for k in range(len(signals)):\n",
    "        # plot qT1 signal against geodesic distances\n",
    "        axs[k ].plot(xdata[k],signals[k])\n",
    "        axs[k ].invert_yaxis()\n",
    "        \n",
    "        peak_color = 0\n",
    "        \n",
    "        axs[k ].plot(xdata[k][0], signals[k][0], color='c', marker='.', markersize=10)\n",
    "        axs[k ].plot(xdata[k][-1], signals[k][-1], color='y', marker='.', markersize=10)\n",
    "        axs[k ].plot(0, signals[k][np.where(xdata[k]==0)[0][0]], color='r', marker='.', markersize=10)\n",
    "        #axs[k ].plot(0, signals[k][np.where(xdata[k]==0)[0][0]], color='r', marker='.', markersize=10)\n",
    "        \n",
    "        for peaks in peaks_m_unq: \n",
    "            for peak in peaks:\n",
    "                if peak[0] == k:\n",
    "                    axs[k ].plot(xdata[peak[0]][peak[1]],signals[peak[0]][peak[1]],marker=\"x\",markeredgewidth=2,color=colors[peak_color])\n",
    "                    axs[k ].vlines(x = xdata[peak[0]][peak[1]], ymin = signals[peak[0]][peak[1]] - peaks_m[1][peak[0]][\"prominences\"][np.where(peaks_m[0][peak[0]]==peak[1])[0]], ymax = signals[peak[0]][peak[1]], color=colors[peak_color])\n",
    "\n",
    "            peak_color = peak_color + 1\n",
    "            \n",
    "        #if datatype != \"detrended\":\n",
    "        #    axs[k ].plot(distance_f_h_all_d2_d1_d10_multi_y[k][len(fhpath[k])+len(d2path[k])-1], qT1_sim_path_d2_d1_d10_multi_y[k][len(fhpath[k])+len(d2path[k])-1], color='m', marker='.', markersize=10)\n",
    "\n",
    "    fig.savefig(outdir+ind+'_'+datatype+'_qT1_signals_final_peaks_seeds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save signal peaks and properties to file\n",
    "# add border_count param to file\n",
    "\n",
    "detrended_signal = detrend_signal(qT1_sim_path_d2_d1_d10_multi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_m = find_prominent_peaks(detrended_signal)\n",
    "print(peaks_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_idx_pairs, signal_pairs = define_comparisons(detrended_signal,peaks_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect borders in the smoothed qT1 signal along normalized geodesic distances\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import more_itertools\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "def init_peak_pairs(peak_idx_pairs, signal_pairs, normalizedData):\n",
    "    yvalues = []\n",
    "    peaks_m_final = []\n",
    "    peaks_m_next_final = []\n",
    "\n",
    "    final = [0,0,0,0,0]\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    pairs = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for k in range(0,len(signal_pairs)):\n",
    "        print(len(peak_idx_pairs))\n",
    "        print(len(signal_pairs))\n",
    "        #print number of detected peaks:\n",
    "        print(\"# of Detected Peaks along path \" + str(signal_pairs[k][0]) + \": \" + str(len(peak_idx_pairs[k][0])))\n",
    "        print(\"# of Detected Peaks along path \" + str(signal_pairs[k][1]) + \": \" + str(len(peak_idx_pairs[k][1])))\n",
    "\n",
    "        index = []\n",
    "        mindiff = []\n",
    "        x = []\n",
    "        xval = []\n",
    "\n",
    "        # find nearest peaks on neighboring geodesic path by comparing differences in normalized geodesic distance:\n",
    "        arr = np.array(normalizedData[signal_pairs[k][1]],dtype=object)\n",
    "        arr = arr[peak_idx_pairs[k][1]]\n",
    "        print(\"Array is : \", arr)\n",
    "\n",
    "        for l in range(0,len(peak_idx_pairs[k][0])):\n",
    "            count = count + 1\n",
    "            print(count)\n",
    "            # element to which nearest value is to be found\n",
    "            x.append(l)\n",
    "            xval.append(normalizedData[signal_pairs[k][0]][peak_idx_pairs[k][0][l]])\n",
    "            print(\"Value to which nearest element is to be found: \", xval[l])\n",
    "\n",
    "            # calculate the difference array\n",
    "            difference_array = np.absolute(arr-xval[l])\n",
    "            signed_difference_array = arr-xval[l]\n",
    "\n",
    "            print(\"signed_difference_array\")\n",
    "            print(signed_difference_array)\n",
    "            \n",
    "            tmp_arr = signed_difference_array[signed_difference_array>0]\n",
    "            \n",
    "            if len(tmp_arr) == 0:\n",
    "                print(\"ONLY NEGATIVE VALUES!!\")\n",
    "            print(tmp_arr)\n",
    "\n",
    "            # find the index of minimum element from the array\n",
    "            try:\n",
    "                if subj==0:\n",
    "                    minidx = difference_array.argmin()\n",
    "                    if signal_pairs[k][0] < signal_pairs[k][1] and abs(signal_pairs[k][0]-signal_pairs[k][1]) > 1 and signed_difference_array[minidx] < -2.5: \n",
    "                        index.append(list(np.where(signed_difference_array==[min(signed_difference_array[signed_difference_array>0])]))[0][0])\n",
    "                    elif signal_pairs[k][0] > signal_pairs[k][1] and abs(signal_pairs[k][0]-signal_pairs[k][1]) > 1 and signed_difference_array[minidx] > 2.5: \n",
    "                        index.append(list(np.where(signed_difference_array==[max(signed_difference_array[signed_difference_array<0])]))[0][0])\n",
    "                    elif signal_pairs[k][0] < signal_pairs[k][1] and abs(signal_pairs[k][0]-signal_pairs[k][1]) == 1 and signed_difference_array[minidx] < -2.5 and difference_array[minidx] > 2.5: \n",
    "                        index.append(list(np.where(signed_difference_array==[min(signed_difference_array[signed_difference_array>0])]))[0][0])\n",
    "                    else:\n",
    "                        index.append(minidx)\n",
    "                else:\n",
    "                    #difference_array = abs(signed_difference_array)\n",
    "                    minidx = difference_array.argmin()\n",
    "                    if signal_pairs[k][0] < signal_pairs[k][1] and abs(signal_pairs[k][0]-signal_pairs[k][1]) > 1 and signed_difference_array[minidx] < -2.5: \n",
    "                        index.append(list(np.where(signed_difference_array==[min(signed_difference_array[signed_difference_array>0])]))[0][0])\n",
    "                    elif signal_pairs[k][0] > signal_pairs[k][1] and abs(signal_pairs[k][0]-signal_pairs[k][1]) > 1 and signed_difference_array[minidx] > 2.5: \n",
    "                        index.append(list(np.where(signed_difference_array==[max(signed_difference_array[signed_difference_array<0])]))[0][0])\n",
    "                    elif signal_pairs[k][0] < signal_pairs[k][1] and abs(signal_pairs[k][0]-signal_pairs[k][1]) == 1 and signed_difference_array[minidx] < -2.5 and difference_array[minidx] > 2.5: \n",
    "                        index.append(list(np.where(signed_difference_array==[min(signed_difference_array[signed_difference_array>0])]))[0][0])\n",
    "                    else:\n",
    "                        index.append(minidx)\n",
    "                    \n",
    "                print(\"Nearest element to the given values is : \", arr[index[l]])\n",
    "                print(\"Index of nearest value is : \", index[l])\n",
    "\n",
    "                print(\"Difference between position of actual value and next value is: \", difference_array[index[l]])\n",
    "                mindiff.append(difference_array[index[l]])\n",
    "\n",
    "                pairs.append([(signal_pairs[k][0],l),(signal_pairs[k][1],index[l]),(difference_array[index[l]]),(signed_difference_array[index[l]])])\n",
    "            except:\n",
    "                print('No valid near neighbor can be detected.')\n",
    "\n",
    "        # only store index of peak if its distance is closer than 0.3 (1/3 of the whole path length) to the previous detected peak\n",
    "        print(\"Initial Pairs:\")\n",
    "        print(pairs)\n",
    "        mindiff_03_idx = np.where(np.array(mindiff)<5.0)[0].tolist()\n",
    "        print(mindiff)\n",
    "        print(mindiff_03_idx)\n",
    "\n",
    "        print(\"Peaks Next: \", index)\n",
    "        peaks_m_next_final.append(np.take(index, mindiff_03_idx).tolist()) \n",
    "        print(\"Peaks Next Final: \",peaks_m_next_final)\n",
    "\n",
    "        unq, unq_idx, unq_cnt = np.unique(index, return_inverse=True, return_counts=True)\n",
    "        cnt_mask = unq_cnt > 1\n",
    "        cnt_unique = unq_cnt == 1\n",
    "        uniques = unq[cnt_unique]\n",
    "        duplicates = unq[cnt_mask]\n",
    "\n",
    "        x_idx = []\n",
    "\n",
    "        for i in range(len(uniques)):\n",
    "            uniques_idx = np.where(index==uniques[i])[0]\n",
    "            print(\"uniques_idx: \", uniques_idx)\n",
    "            x_idx.append(uniques_idx)\n",
    "\n",
    "        for i in range(len(duplicates)):\n",
    "            duplicates_idx = np.where(index==duplicates[i])[0]\n",
    "            mindiff_min_idx = np.take(mindiff,duplicates_idx).argmin()\n",
    "            x_idx.append(np.take(duplicates_idx,mindiff_min_idx))\n",
    "\n",
    "        flat_x_idx = list(more_itertools.collapse(x_idx))\n",
    "        print(\"Flat list: \",flat_x_idx)\n",
    "\n",
    "        fin_x_idx = []\n",
    "        for i in flat_x_idx:\n",
    "            print(i)\n",
    "            if mindiff[i] < 5.0:\n",
    "                fin_x_idx.append(x[i])\n",
    "\n",
    "        peaks_m_final.append(fin_x_idx)\n",
    "\n",
    "    print(count)\n",
    "    print(\"Pairs: \", pairs)\n",
    "    for r in pairs:\n",
    "        if r[2] > 5.0:\n",
    "            pairs.remove(r)\n",
    "    print(\"Pairs after removing pairs of high diffs: \", pairs)\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "pairs = init_peak_pairs(peak_idx_pairs, signal_pairs, normalizedData)\n",
    "\n",
    "copy_pairs = pairs\n",
    "\n",
    "init_pairs = [sublist[0:2] for sublist in pairs]\n",
    "print(init_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersections(pairs):\n",
    "    # check for all 1st valleys which have the same 2nd valley and only keep those valley pairs with the minimum distance\n",
    "    last_valleys = [sublist[-3] for sublist in pairs]\n",
    "    duplicates=[]\n",
    "    indices=[]\n",
    "    count = 0\n",
    "    for i, tuple_ in enumerate(last_valleys):\n",
    "        print(i)\n",
    "        print(\"Tuple_: \",tuple_)\n",
    "        pairs[i].append(i)\n",
    "        if last_valleys.count(tuple_) > 1:\n",
    "            duplicates.append(pairs[i])\n",
    "            print(duplicates)\n",
    "            print(duplicates[count])\n",
    "            #duplicates[count].append(i)\n",
    "            indices.append(i)\n",
    "            count = count + 1\n",
    "    print(\"Sublists with duplicate 2nd valleys: \", duplicates)\n",
    "    print(\"Indices of Duplicates: \", indices)\n",
    "\n",
    "    maxvalley2_idx = []\n",
    "    grouped_sublists = {}\n",
    "\n",
    "    for sublist in duplicates:\n",
    "        last_tuple = sublist[1]\n",
    "        if last_tuple in grouped_sublists:\n",
    "            grouped_sublists[last_tuple].append(sublist)\n",
    "        else:\n",
    "            grouped_sublists[last_tuple] = [sublist]\n",
    "    print(grouped_sublists)\n",
    "    print(len(grouped_sublists.items()))\n",
    "\n",
    "    maxvalley2 = []\n",
    "    print(maxvalley2)\n",
    "    #count = 0\n",
    "\n",
    "    for key,value in grouped_sublists.items():\n",
    "        print(value)\n",
    "        #print(count)\n",
    "        #print(maxvalley2[count])\n",
    "        diffvalues = []\n",
    "        for i in range(len(value)):\n",
    "            print(len(value))\n",
    "            print(value[i][0])\n",
    "            print(value[i][-3])\n",
    "            diffvalues.append(value[i][0:4])\n",
    "        maxvalley2.append(diffvalues)\n",
    "        #count = count + 1\n",
    "    print(\"Maxvalley2:\")\n",
    "    print(maxvalley2)\n",
    "\n",
    "    for i in range(len(maxvalley2)):\n",
    "        \n",
    "        if subj==0:\n",
    "            for dupl in maxvalley2[i]:\n",
    "            ### more advanced decision criterion on which valleys are to be removed ###\n",
    "                if dupl[0][0] < dupl[1][0] and abs(dupl[0][0]-dupl[1][0]) > 1 and dupl[3] < 0: \n",
    "                    dupl[2] = np.nan\n",
    "                elif dupl[0][0] > dupl[1][0] and abs(dupl[0][0]-dupl[1][0]) > 1 and dupl[3] > 0: \n",
    "                    dupl[2] = np.nan\n",
    "\n",
    "        abs_dist = [elem[2] for elem in maxvalley2[i]]\n",
    "\n",
    "        print(\"Absolute Differences after setting wrong direction elements to nan\")\n",
    "        print(abs_dist)\n",
    "        print(np.nanargmin(abs_dist))\n",
    "        maxvalley2_idx.append(np.nanargmin(abs_dist))\n",
    "\n",
    "    print(\"maxvalley2_idx\")\n",
    "    print(maxvalley2_idx)\n",
    "\n",
    "    remove_valleys = []\n",
    "    count = 0\n",
    "    for key,value in grouped_sublists.items():\n",
    "        print(\"Value:\")\n",
    "        print(value)\n",
    "        rvalues = []\n",
    "        value.pop(maxvalley2_idx[count])\n",
    "        for i in range(len(value)):\n",
    "            rvalues.append([value[i][-1]])\n",
    "            #value[i].pop(-1)\n",
    "        remove_valleys.append(rvalues)\n",
    "        #print(value[count])\n",
    "        print(value)\n",
    "        count = count +1\n",
    "    print(\"Valleys to be removed: \", remove_valleys)\n",
    "\n",
    "    flat_remove_valley = list(more_itertools.collapse(remove_valleys))\n",
    "\n",
    "    # remove sublists containing 2nd valley with higher distance from border pairs\n",
    "    rpairs = [ele for idx, ele in enumerate(pairs) if idx not in flat_remove_valley]\n",
    "    print(\"RPAIRS: \", rpairs)\n",
    "\n",
    "    tmp = []\n",
    "    rpairs_fin = []\n",
    "    for elem in rpairs:\n",
    "        if elem[2] > 4 and abs(elem[0][0]-elem[1][0]) > 1 and elem[0][0] < elem[1][0] and elem[3] < 0:\n",
    "            tmp.append(elem)\n",
    "        else:\n",
    "            rpairs_fin.append(elem)\n",
    "\n",
    "    print(\"rpairs_fin:\")\n",
    "    print(rpairs_fin)\n",
    "\n",
    "    remove=[]\n",
    "    for i in range(len(rpairs_fin)):\n",
    "        if rpairs_fin[i][-3] > 5.0:\n",
    "            remove.append(rpairs_fin[i])\n",
    "\n",
    "    for i in remove:\n",
    "        rpairs_fin.remove(i)\n",
    "    print((\"RPAIRS_fin: \", rpairs_fin))\n",
    "\n",
    "    # remove diff and ID distance tuple from all pairs of remaining neighboring valleys\n",
    "    fpairs = [sublist[:-3] for sublist in rpairs_fin]\n",
    "    print(\"Pairs after removing diff tuple: \", fpairs)\n",
    "\n",
    "    # create feature matrix of remaining valleys\n",
    "    print(\"Valley Properties: \", properties_m)\n",
    "\n",
    "    ufpairs = list(set(chain.from_iterable(fpairs)))\n",
    "    print(ufpairs)\n",
    "\n",
    "    prominence = []\n",
    "    height = []\n",
    "    width = []\n",
    "\n",
    "    for valley in ufpairs:\n",
    "        prominence.append(properties_m[valley[0]][\"prominences\"][valley[1]])\n",
    "        height.append(properties_m[valley[0]][\"peak_heights\"][valley[1]])\n",
    "        width.append(properties_m[valley[0]][\"widths\"][valley[1]])\n",
    "    print(\"Prominences: \", prominence)\n",
    "    \n",
    "    return fpairs, ufpairs\n",
    "\n",
    "fpairs, ufpairs = find_intersections(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_intersecting_lists(lists):\n",
    "    import networkx as nx\n",
    "    g = nx.Graph()\n",
    "\n",
    "    for sub_list in lists:\n",
    "        for i in range(1,len(sub_list)):\n",
    "            g.add_edge(sub_list[0],sub_list[i])\n",
    "    \n",
    "    merged_list = list(nx.connected_components(g))\n",
    "    print(merged_list)\n",
    "    return merged_list\n",
    "\n",
    "# merge valleys with intersections together to obtain groups of neighboring valleys which shape a border\n",
    "merged_list = merge_intersecting_lists(fpairs)\n",
    "print(\"Merged Lists: \", merged_list) #represent border groups\n",
    "print(len(merged_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only those goups are considered as real borders which have a minmum length of 3 (i.e., occur across a minmum of 3 paths)\n",
    "def check_min_length(merged_list):\n",
    "    fmerged_list = merged_list\n",
    "    len(fmerged_list)\n",
    "    fmerged_remove = []\n",
    "    for i in fmerged_list:\n",
    "        if len(i) < 3:\n",
    "            fmerged_remove.append(i)\n",
    "    for remove in fmerged_remove:\n",
    "        fmerged_list.remove(remove)\n",
    "    return fmerged_list\n",
    "\n",
    "fmerged_list = check_min_length(merged_list)\n",
    "print(\"Final Merged List: \", fmerged_list)\n",
    "print(len(fmerged_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_peaks(result):\n",
    "    result = list(result)\n",
    "    for it in range(0,len(result)):\n",
    "        result[it] = list(result[it])\n",
    "        for i in range(0,len(result[it])):\n",
    "            result[it][i] = list(result[it][i])\n",
    "            result[it][i][1] = peaks_m[0][result[it][i][0]][result[it][i][1]]\n",
    "    print(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "result = get_original_peaks(fmerged_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_border_peaks(result,number,normalizedData):\n",
    "    number_signals = list(range(0,number))\n",
    "    print(number_signals)\n",
    "    count = [[] for i in range(0,number)]\n",
    "    tmp = [[] for i in range(0,number)]\n",
    "    i = 0\n",
    "    multiple = False\n",
    "    new_res = result\n",
    "    \n",
    "    print(result)\n",
    "    \n",
    "    rmv_check = [[] for i in range(0,number)]\n",
    "    \n",
    "    max_gdist = []\n",
    "    \n",
    "    for res in result:\n",
    "        \n",
    "        res.sort(key=lambda sublist: sublist[0])\n",
    "        \n",
    "        index_count = [[] for i in range(0,number)]\n",
    "        rmv = []\n",
    "        gdist = []        \n",
    "        \n",
    "        for num in number_signals:\n",
    "            j = 0\n",
    "            print(\"Signal Number:\")\n",
    "            print(num)\n",
    "            count[i].append(sum(item[0]==num for item in res))\n",
    "            print(\"Number of Peaks per Signal in Group:\")\n",
    "            print(count[i])\n",
    "            \n",
    "            if count[i][num] > 1:\n",
    "                resfirst = [item[0] for item in res]\n",
    "                for it in range(0,len(resfirst)):\n",
    "                    if resfirst[it] == num:\n",
    "                        index_count[num].append(it)\n",
    "                    print(\"Index Count:\")\n",
    "                    print(index_count)\n",
    "        \n",
    "                #min(signed_difference_array[signed_difference_array>0])\n",
    "        for index in index_count:\n",
    "            print(\"INDEX\")\n",
    "            print(index)\n",
    "            if len(index) > 0:\n",
    "                print(\"testtest\")\n",
    "                print(res)\n",
    "                tmp[i].append(np.array(res)[index].tolist())\n",
    "            \n",
    "            print(\"Duplicates:\")\n",
    "            print(tmp[i])\n",
    "        \n",
    "        for t in tmp[i]:\n",
    "            gdist = []\n",
    "            if len(t) > 1:\n",
    "                multiple = True\n",
    "                resfirst = [item[0] for item in res]\n",
    "                ressecond = [item[1] for item in res]\n",
    "\n",
    "                neighbors = abs(np.array(resfirst)-t[0][0])\n",
    "                print(\"Neighbors to Duplicate:\")\n",
    "                print(neighbors)\n",
    "\n",
    "                nearest_neighbor = np.where(neighbors == min(neighbors[neighbors>0]))[0][0]\n",
    "                print('nearest_neighbor')\n",
    "                print(nearest_neighbor)\n",
    "\n",
    "                for tt in t:\n",
    "                    print('tt')\n",
    "                    print(tt)\n",
    "                    gdist_tmp = normalizedData[tt[0]][tt[1]] - normalizedData[resfirst[nearest_neighbor]][ressecond[nearest_neighbor]]\n",
    "                    \n",
    "                    #if (tt[0] > resfirst[nearest_neighbor] and gdist_tmp > -2.49) or tt[0] < resfirst[nearest_neighbor]: \n",
    "                    if gdist_tmp < -2.5:\n",
    "                        gdist.append(9999)\n",
    "                    else:\n",
    "                        gdist.append(gdist_tmp)\n",
    "                \n",
    "                print('gdist')       \n",
    "                print(gdist)\n",
    "                \n",
    "                try:\n",
    "                    max_gdist = np.argmax(np.absolute(gdist))\n",
    "                    rmv.append(t[max_gdist])\n",
    "                    print(max_gdist)\n",
    "                except:\n",
    "                    print('Nothing to remove. Try next.')\n",
    "                    \n",
    "                res = [ele for ele in res if ele not in rmv]\n",
    "                \n",
    "                    #print(resfirst[nearest_neighbor])\n",
    "                    #print(t[0])\n",
    "                    #if resfirst[nearest_neighbor] < t[0] and abs(resfirst[nearest_neighbor]-t[0]) > 0 and normalizedData[t[0]][t[1]] - normalizedData[resfirst[nearest_neighbor]][ressecond[nearest_neighbor]] < 0:\n",
    "                    #    rmv.append(t)\n",
    "                    #elif resfirst[nearest_neighbor] > t[0] and abs(resfirst[nearest_neighbor]-t[0]) > 0 and normalizedData[t[0]][t[1]] - normalizedData[resfirst[nearest_neighbor]][ressecond[nearest_neighbor]] > 0:\n",
    "                    #    rmv.append(t)\n",
    "        \n",
    "        rmv_check[i] = rmv   \n",
    "        \n",
    "        new_res[i] = [ele for ele in res if ele not in rmv]\n",
    "        print(new_res[i])\n",
    "        \n",
    "        new_res[i].sort()\n",
    "        print(new_res[i])\n",
    "                   \n",
    "        if len(new_res[i]) < 3:\n",
    "            new_res[i] = []            \n",
    "            \n",
    "        i = i +1\n",
    "    \n",
    "    result = new_res\n",
    "    \n",
    "    rmv = []\n",
    "    \n",
    "    y = 0\n",
    "        \n",
    "    for r in result:\n",
    "        norm_result = []\n",
    "        print(r)\n",
    "        for i in r:\n",
    "            print(i[0])\n",
    "            print(normalizedData[i[0]][20])\n",
    "            norm_result.append(normalizedData[i[0]][i[1]])\n",
    "        \n",
    "        #print(norm_result)\n",
    "        \n",
    "        grad_result = np.gradient(norm_result)\n",
    "        \n",
    "        print(grad_result)\n",
    "        \n",
    "        #print(abs(grad_result))\n",
    "        \n",
    "        #print(2*np.std(abs(grad_result)))\n",
    "        \n",
    "        #std_grad_result = 2*np.std(abs(grad_result))\n",
    "        \n",
    "        #print(np.gradient(grad_result))\n",
    "        \n",
    "        #print(np.std(np.gradient(grad_result)))\n",
    "        \n",
    "        # IQR\n",
    "        # Find Q1, Q3\n",
    "        # 1.\n",
    "        #Q1 = np.percentile((grad_result) , 25)\n",
    "        #Q3 = np.percentile((grad_result) , 75)\n",
    "\n",
    "        # 2.\n",
    "        #Q1,Q3 = np.percentile((abs(grad_result)) , [25,75])\n",
    "\n",
    "        #Find IQR, upper limit, lower limit\n",
    "        #IQR = Q3 - Q1\n",
    "        #ul = Q3+1.5*IQR\n",
    "        #ll = Q1-1.5*IQR\n",
    "        \n",
    "        #print(ul)\n",
    "        #print(ll)\n",
    "\n",
    "        abs_grad_result = abs(grad_result)\n",
    "        \n",
    "        # Find outliers\n",
    "        #outliers = abs_grad_result[(abs_grad_result > ul) | (abs_grad_result < ll)]\n",
    "        #outliers = list(np.where(abs_grad_result > std_grad_result))[0]\n",
    "        outliers = np.where(abs_grad_result > 5)[0]\n",
    "        print(outliers)\n",
    "        \n",
    "        for out in outliers:\n",
    "            rmv_check[y].append(r[out])\n",
    "        \n",
    "        print(rmv)\n",
    "        \n",
    "        result[y] = [ele for ele in r if ele not in rmv_check[y]]\n",
    "        \n",
    "        y = y + 1\n",
    "        \n",
    "    for elem in range(0, len(result)):\n",
    "        if len(result[elem]) < 3:\n",
    "            result[elem] = []\n",
    "        \n",
    "    print(result)\n",
    "    \n",
    "    result = [ele for ele in result if len(ele) > 0]\n",
    "    \n",
    "    print(result)\n",
    "    \n",
    "    rmv_check.append(rmv)\n",
    "    \n",
    "    print(rmv_check)\n",
    "        \n",
    "    for elem in rmv_check:\n",
    "        if len(elem) > 2:\n",
    "            result.append(elem)\n",
    "    \n",
    "    print(result)\n",
    "    \n",
    "    sorted_result = sorted(result, key=lambda sublist: sublist[0][1])\n",
    "    \n",
    "    print(sorted_result)\n",
    "    \n",
    "    return sorted_result\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = len(detrended_signal)\n",
    "final_result = check_border_peaks(result,number,normalizedData)\n",
    "\n",
    "# exctract number of detected borders\n",
    "border_count = len(final_result)\n",
    "print(border_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datat = \"raw\"\n",
    "plot_signals(final_result,qT1_sim_path_d2_d1_d10_multi_y,distance_f_h_all_d2_d1_d10_multi_y,qT1_sim_path_f_h_full_multi_y,qT1_sim_path_h_d2_full_multi_y,datat,peaks_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_f_h_all_d2_d1_d10_multi_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datat = \"detrended\"\n",
    "plot_signals(final_result,detrended_signal,distance_f_h_all_d2_d1_d10_multi_y,qT1_sim_path_f_h_full_multi_y,qT1_sim_path_h_d2_full_multi_y,datat,peaks_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map extracted borders back to surface\n",
    "######################################################\n",
    "# middle qT1\n",
    "\n",
    "crgb = [\"darkorange\",\"darkcyan\",\"darkviolet\",\"darkred\",\"darkgreen\",\"darkblue\"]\n",
    "#crgb = (\"r\",\"c\",\"g\",\"y\",\"b\")\n",
    "\n",
    "#border_loc_mesh = sum(result, [])\n",
    "border_loc_mesh = final_result\n",
    "print(border_loc_mesh)\n",
    "\n",
    "merged_path = [pv.PolyData(),pv.PolyData(),pv.PolyData(),pv.PolyData(),pv.PolyData()]\n",
    "\n",
    "for i in range(len(path_f_h_full_multi_yred)):\n",
    "    \n",
    "    final_path_length = len(path_f_h_full_multi_yred[i].points) + len(path_d2_d5_full_multi_yred[i].points) - 1\n",
    "    print(len(path_f_h_full_multi_yred[i].points) + len(path_d2_d5_full_multi_yred[i].points) - 1)\n",
    "    \n",
    "    #merging in this way ensures that superior path is written to the end of the array and borders appear in the correct order on the surface\n",
    "    merged_path[i] = path_d2_d5_full_multi_yred[i].merge(path_f_h_full_multi_yred[i])\n",
    "\n",
    "    if final_path_length == len(merged_path[i].points):\n",
    "        path_msg = \"Border correctly projected. Correct final path langths.\"\n",
    "    else:\n",
    "        path_msg = \"Borders may not be correctly projected. Mismatch in final path langths. Check merged_path variable.\"\n",
    "    \n",
    "    print(len(merged_path[i].points))\n",
    "    \n",
    "    print(path_d2_d5_full_multi_yred[i].points)\n",
    "    print(merged_path[i].points)\n",
    "    \n",
    "print(merged_path)\n",
    "\n",
    "yrange = [0,1,2,3,4]\n",
    "i=0\n",
    "\n",
    "#plot surface\n",
    "p4 = pv.Plotter()\n",
    "p4.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        print(border_loc_mesh[k])\n",
    "        p4.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=6, color = crgb[k])\n",
    "        print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "        p4.add_mesh(merged_path[border_loc_mesh[k][i][0]])\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.show()\n",
    "\n",
    "#save surface plot\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p4.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=6, color = crgb[k])\n",
    "        print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.screenshot(outdir+ind+'_qT1_signal_final_borders_smooth.png',transparent_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p4_camera_position = [(93.96340522180034, 62.05208176751892, -4.599802458284934),\n",
    "#(23.958131814789642, 78.3841590360701, 63.502972950631026),\n",
    "#(-0.6601009969549828, -0.5029854388605619, -0.5579178453081473)]\n",
    "\n",
    "#pv.global_theme.anti_aliasing = 'ssaa'\n",
    "\n",
    "#plot surface\n",
    "p4 = pv.Plotter()\n",
    "p4.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p4.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=6, color = crgb[k])\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.camera.zoom(2.0)\n",
    "#p4.enable_anti_aliasing('msaa')\n",
    "#p4.camera.view_frustum(1.0)\n",
    "#p4.camera.view_angle = 20\n",
    "p4.show()\n",
    "\n",
    "#save surface plot\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p4.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=6, color = crgb[k])\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.camera.zoom(2.0)\n",
    "p4.screenshot(outdir+ind+'_qT1_signal_final_borders_smooth_zoomed.png',transparent_background=True, window_size=(500,950))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p4_camera_position = [(93.96340522180034, 62.05208176751892, -4.599802458284934),\n",
    "#(23.958131814789642, 78.3841590360701, 63.502972950631026),\n",
    "#(-0.6601009969549828, -0.5029854388605619, -0.5579178453081473)]\n",
    "\n",
    "#pv.global_theme.anti_aliasing = 'ssaa'\n",
    "\n",
    "#plot surface\n",
    "p4 = pv.Plotter()\n",
    "p4.add_mesh(mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p4.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=6, color = crgb[k])\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.camera.zoom(2.0)\n",
    "#p4.enable_anti_aliasing('msaa')\n",
    "#p4.camera.view_frustum(1.0)\n",
    "#p4.camera.view_angle = 20\n",
    "p4.show()\n",
    "\n",
    "#save surface plot\n",
    "p4 = pv.Plotter(off_screen=True)\n",
    "p4.add_mesh(mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p4.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=6, color = crgb[k])\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "p4.camera_position = p4_camera_position\n",
    "p4.camera.zoom(2.0)\n",
    "p4.screenshot(outdir+ind+'_qT1_signal_final_borders_orig_zoomed.png',transparent_background=True, window_size=(500,950))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_params, header = get_border_params(final_result,peaks_m,qT1_sim_path_d2_d1_d10_multi_y,qT1_im_path_d2_d1_d10_multi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_points_to_vtk(array_of_polyData, points):\n",
    "    \n",
    "    combined_points = []\n",
    "    mesh = []\n",
    "    \n",
    "    for k in range(len(points)):\n",
    "        p4.add_points(array_of_polyData[points[k][0]].points[points[k][1],:], point_size=6, color = 'r')\n",
    "        print(array_of_polyData[points[k][0]].points[points[k][1],:])\n",
    "    \n",
    "    for k in range(len(points)):\n",
    "        combined_points.append(array_of_polyData[points[k][0]].points[points[k][1],:])\n",
    "        mesh.append(array_of_polyData[points[k][0]].extract_points(points[k][1],adjacent_cells = False, include_cells = False))\n",
    "    \n",
    "    combined_mesh = mesh[0]\n",
    "    for m in range(len(mesh)-1):\n",
    "        combined_mesh = combined_mesh.merge(mesh[m+1])\n",
    "    \n",
    "    print(combined_points)\n",
    "    print(mesh)\n",
    "    print(combined_mesh)\n",
    "    \n",
    "    combined_mesh.save(outdir+ind+'_extracted_borders.vtk')\n",
    "\n",
    "    return combined_mesh\n",
    "\n",
    "border_loc_mesh_new = sum(list(border_loc_mesh), [])\n",
    "\n",
    "try:\n",
    "    mesh = write_points_to_vtk(merged_path,border_loc_mesh_new)\n",
    "    #plot surface\n",
    "    p4 = pv.Plotter()\n",
    "    p4.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "    p4.add_mesh(mesh, point_size=6, color=\"m\")\n",
    "    p4.camera_position = p4_camera_position\n",
    "    p4.show()\n",
    "except:\n",
    "    print(\"No Borders identified that can be stored to vtk file.\")\n",
    "\n",
    "try:\n",
    "    meshn = pv.read(outdir+ind+'_extracted_borders.vtk')\n",
    "    p4 = pv.Plotter()\n",
    "    p4.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "    p4.add_mesh(meshn, point_size=6, color=\"m\")\n",
    "    p4.camera_position = p4_camera_position\n",
    "    p4.show()\n",
    "except:\n",
    "    print(\"No Borders identified that can be loaded from vtk file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_mesh_qT1_im.translate((-0.015,0,0))\n",
    "\n",
    "#plot surface\n",
    "p3 = pv.Plotter()\n",
    "p3.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\",show_scalar_bar=False)\n",
    "p3.add_mesh(mesh_f, opacity='linear', cmap=my_colormap_d1, show_scalar_bar=False)\n",
    "p3.add_mesh(mesh_h, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "p3.add_mesh(test_yh_red, point_size=8, color='r')\n",
    "p3.add_mesh(test_yf_red,point_size=8, color='c')\n",
    "p3.add_mesh(test_yd5_red,point_size=8, color='y')\n",
    "#p3.add_mesh(mesh_d5, opacity='linear', cmap=my_colormap_d5, show_scalar_bar=False)\n",
    "\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p3.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=9, color = crgb[k])\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "p3.camera_position = p4_camera_position\n",
    "p3.camera.zoom(2.0)\n",
    "#p4.enable_anti_aliasing('msaa')\n",
    "#p4.camera.view_frustum(1.0)\n",
    "#p4.camera.view_angle = 20\n",
    "p3.show()\n",
    "\n",
    "#save surface plot\n",
    "p3 = pv.Plotter(off_screen=True)\n",
    "p3.set_background('white')\n",
    "p3.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\", show_scalar_bar=False)\n",
    "p3.add_mesh(mesh_f, opacity='linear', cmap=my_colormap_d1, show_scalar_bar=False)\n",
    "p3.add_mesh(mesh_h, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "#p3.add_mesh(mesh_d5, opacity='linear', cmap=my_colormap_d5, show_scalar_bar=False)\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p3.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=10, color = crgb[k])\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "p3.camera_position = p4_camera_position\n",
    "p3.camera.zoom(2.0)\n",
    "p3.screenshot(outdir+ind+'_qT1_signal_final_borders_smooth_zoomed_pRF.png', window_size=(500,950))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_mesh_qT1_im.translate((-0.015,0,0))\n",
    "\n",
    "#plot surface\n",
    "p2 = pv.Plotter()\n",
    "p2.set_background('white')\n",
    "p2.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\",show_scalar_bar=False)\n",
    "p2.add_mesh(mesh_f, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "p2.add_mesh(mesh_h, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p2.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=9, color = \"white\")\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "p2.camera_position = p4_camera_position\n",
    "p2.camera.zoom(2.0)\n",
    "#p4.enable_anti_aliasing('msaa')\n",
    "#p4.camera.view_frustum(1.0)\n",
    "#p4.camera.view_angle = 20\n",
    "p2.show()\n",
    "\n",
    "#save surface plot\n",
    "p2 = pv.Plotter(off_screen=True)\n",
    "p2.set_background('white')\n",
    "p2.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\", show_scalar_bar=False)\n",
    "p2.add_mesh(mesh_f, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "p2.add_mesh(mesh_h, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p2.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=10, color = \"white\")\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "p2.camera_position = p4_camera_position\n",
    "p2.camera.zoom(2.0)\n",
    "p2.screenshot(outdir+ind+'_qT1_signal_final_borders_smooth_zoomed_pRF_white.png', window_size=(500,950))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_mesh_qT1_im.translate((-0.015,0,0))\n",
    "\n",
    "#plot surface\n",
    "p2 = pv.Plotter()\n",
    "p2.set_background('white')\n",
    "p2.add_mesh(mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\",show_scalar_bar=False)\n",
    "p2.add_mesh(mesh_f, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "p2.add_mesh(mesh_h, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p2.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=9, color = \"white\")\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "p2.camera_position = p4_camera_position\n",
    "p2.camera.zoom(2.0)\n",
    "#p4.enable_anti_aliasing('msaa')\n",
    "#p4.camera.view_frustum(1.0)\n",
    "#p4.camera.view_angle = 20\n",
    "p2.show()\n",
    "\n",
    "#save surface plot\n",
    "p2 = pv.Plotter(off_screen=True)\n",
    "p2.set_background('white')\n",
    "p2.add_mesh(mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\", show_scalar_bar=False)\n",
    "p2.add_mesh(mesh_f, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "p2.add_mesh(mesh_h, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p2.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=10, color = \"white\")\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "p2.camera_position = p4_camera_position\n",
    "p2.camera.zoom(2.0)\n",
    "p2.screenshot(outdir+ind+'_qT1_signal_final_borders_orig_zoomed_pRF_white.png', window_size=(500,950))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_mesh_qT1_im.translate((-0.015,0,0))\n",
    "\n",
    "#plot surface\n",
    "p = pv.Plotter()\n",
    "p.set_background('white')\n",
    "p.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\",show_scalar_bar=False)\n",
    "p.add_mesh(mesh_f, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "p.add_mesh(mesh_h, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "\n",
    "p.camera_position = p4_camera_position\n",
    "p.camera.zoom(2.0)\n",
    "#p4.enable_anti_aliasing('msaa')\n",
    "#p4.camera.view_frustum(1.0)\n",
    "#p4.camera.view_angle = 20\n",
    "p.show()\n",
    "\n",
    "#save surface plot\n",
    "p = pv.Plotter(off_screen=True)\n",
    "p.set_background('white')\n",
    "p.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\", show_scalar_bar=False)\n",
    "p.add_mesh(mesh_f, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "p.add_mesh(mesh_h, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "\n",
    "p.camera_position = p4_camera_position\n",
    "p.camera.zoom(2.0)\n",
    "p.screenshot(outdir+ind+'_qT1_signal_pRF.png', window_size=(500,950))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot surface\n",
    "p5 = pv.Plotter()\n",
    "p5.set_background('white')\n",
    "p5.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p5.camera_position = p4_camera_position\n",
    "p5.show()\n",
    "\n",
    "#plot surface\n",
    "p5 = pv.Plotter()\n",
    "p5.set_background('white')\n",
    "p5.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p5.camera_position = p4_camera_position\n",
    "p5.screenshot(outdir+ind+'_qT1_signal_smooth.png')\n",
    "\n",
    "#plot surface\n",
    "p5 = pv.Plotter()\n",
    "p5.set_background('white')\n",
    "p5.add_mesh(smooth_mesh_qT1_im, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\")\n",
    "p5.camera_position = p4_camera_position\n",
    "p5.camera.zoom(2.0)\n",
    "p5.screenshot(outdir+ind+'_qT1_signal_smooth_zoomed.png', window_size=(500,950))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot surface\n",
    "p3 = pv.Plotter()\n",
    "p3.set_background('white')\n",
    "try:\n",
    "    p3.add_mesh(mesh_h, cmap=\"RdPu\", clim=[0, mesh_h[\"EmbedVertex\"].max()],show_scalar_bar=False)\n",
    "except:\n",
    "    print(\"No motor localizer.\")\n",
    "    \n",
    "#for k in range(len(border_loc_mesh)):\n",
    "#    for i in range(0,len(border_loc_mesh[k])):\n",
    "#        p3.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=9, color = crgb[k])\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "p3.camera_position = p4_camera_position\n",
    "p3.camera.zoom(2.0)\n",
    "p3.show()\n",
    "\n",
    "#save surface plot\n",
    "p3 = pv.Plotter(off_screen=True)\n",
    "p3.set_background('white')\n",
    "try:\n",
    "    p3.add_mesh(mesh_h, cmap=\"RdPu\", clim=[0, mesh_h[\"EmbedVertex\"].max()],show_scalar_bar=False)\n",
    "except:\n",
    "    print(\"No motor localizer.\")\n",
    "    \n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p3.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=10, color = crgb[k])\n",
    "        \n",
    "p3.camera_position = p4_camera_position\n",
    "p3.camera.zoom(2.0)\n",
    "p3.screenshot(outdir+ind+'_qT1_signal_final_borders_smooth_zoomed_motorloc_h.png', window_size=(500,950))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot surface\n",
    "p3 = pv.Plotter()\n",
    "p3.set_background('white')\n",
    "try:\n",
    "    p3.add_mesh(mesh_h, cmap=\"RdPu\", clim=[0, mesh_h[\"EmbedVertex\"].max()],show_scalar_bar=False)\n",
    "except:\n",
    "    print(\"No motor localizer.\")\n",
    "    \n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p3.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=9, color = \"black\")\n",
    "        \n",
    "p3.camera_position = p4_camera_position\n",
    "p3.camera.zoom(2.0)\n",
    "p3.show()\n",
    "\n",
    "#save surface plot\n",
    "p3 = pv.Plotter(off_screen=True)\n",
    "p3.set_background('white')\n",
    "try:\n",
    "    p3.add_mesh(mesh_h, cmap=\"RdPu\", clim=[0, mesh_h[\"EmbedVertex\"].max()],show_scalar_bar=False)\n",
    "except:\n",
    "    print(\"No motor localizer.\")\n",
    "    \n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p3.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=10, color = \"black\")\n",
    "        \n",
    "p3.camera_position = p4_camera_position\n",
    "p3.camera.zoom(2.0)\n",
    "p3.screenshot(outdir+ind+'_qT1_signal_final_borders_smooth_zoomed_motorloc_h_black.png', window_size=(500,950))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate binary BA3b mask #\n",
    "tmp = mesh_qT1_im\n",
    "tmp0 = tmp['EmbedVertex']\n",
    "tmp0[tmp0>0] = 1\n",
    "tmp['EmbedVertex'] = tmp0\n",
    "\n",
    "bg=smooth_mesh_qT1_im\n",
    "bgv=bg['EmbedVertex']\n",
    "bgv[bgv>0] = 0\n",
    "bg['EmbedVertex']=bgv\n",
    "\n",
    "#plot surface\n",
    "p0 = pv.Plotter()\n",
    "p0.set_background('white')\n",
    "p0.add_mesh(bg, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\",show_scalar_bar=False)\n",
    "p0.add_mesh(mesh_f, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "p0.add_mesh(mesh_h, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p0.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=9, color = crgb[k])\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "\n",
    "p0.camera_position = p4_camera_position\n",
    "p0.camera.zoom(2.0)\n",
    "#p4.enable_anti_aliasing('msaa')\n",
    "#p4.camera.view_frustum(1.0)\n",
    "#p4.camera.view_angle = 20\n",
    "p0.show()\n",
    "\n",
    "#save surface plot\n",
    "p0 = pv.Plotter(off_screen=True)\n",
    "p0.set_background('white')\n",
    "p0.add_mesh(bg, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\", show_scalar_bar=False)\n",
    "p0.add_mesh(mesh_f, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "p0.add_mesh(mesh_h, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p0.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=10, color = crgb[k])\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "\n",
    "p0.camera_position = p4_camera_position\n",
    "p0.camera.zoom(2.0)\n",
    "p0.screenshot(outdir+ind+'_qT1_signal_final_borders_smooth_zoomed_pRF_plain.png', window_size=(500,950))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot surface\n",
    "p0 = pv.Plotter()\n",
    "p0.set_background('white')\n",
    "p0.add_mesh(bg, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\",show_scalar_bar=False)\n",
    "p0.add_mesh(mesh_d1, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "p0.add_mesh(mesh_d2, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p0.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=9, color = \"black\")\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "\n",
    "p0.camera_position = p4_camera_position\n",
    "p0.camera.zoom(2.0)\n",
    "#p4.enable_anti_aliasing('msaa')\n",
    "#p4.camera.view_frustum(1.0)\n",
    "#p4.camera.view_angle = 20\n",
    "p0.show()\n",
    "\n",
    "#save surface plot\n",
    "p0 = pv.Plotter(off_screen=True)\n",
    "p0.set_background('white')\n",
    "p0.add_mesh(bg, cmap=qT1_cmap, clim=[mean_im-(4*sd_im), mean_im+(4*sd_im)],below_color=\"#ffffff\", show_scalar_bar=False)\n",
    "p0.add_mesh(mesh_d1, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "p0.add_mesh(mesh_d2, opacity='linear', cmap=my_colormap_d2, show_scalar_bar=False)\n",
    "\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        p0.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=10, color = \"black\")\n",
    "        #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "\n",
    "p0.camera_position = p4_camera_position\n",
    "p0.camera.zoom(2.0)\n",
    "p0.screenshot(outdir+ind+'_qT1_signal_final_borders_smooth_zoomed_pRF_plain_black.png', window_size=(500,950))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load QSM WB\n",
    "if subj == 0:\n",
    "    folder_qsm = 'dummy_data/one_hander/'+ind+'_middle_sQSM_left_orig.vtk'\n",
    "    folder_pqsm = 'dummy_data/one_hander/'+ind+'_middle_pQSM_left_orig.vtk'\n",
    "    folder_nqsm = 'dummy_data/one_hander/'+ind+'_middle_nQSM_left_orig.vtk'\n",
    "else:\n",
    "    folder_qsm = 'dummy_data/one_hander/'+ind+'_middle_sQSM_right_orig.vtk'\n",
    "    folder_pqsm = 'dummy_data/one_hander/'+ind+'_middle_pQSM_right_orig.vtk'\n",
    "    folder_nqsm = 'dummy_data/one_hander/'+ind+'_middle_nQSM_right_orig.vtk'\n",
    "\n",
    "mesh_qsm = pv.PolyData()\n",
    "mesh_pqsm = pv.PolyData()\n",
    "mesh_nqsm = pv.PolyData()\n",
    "\n",
    "try:\n",
    "    mesh_qsm = pv.read(folder_qsm)\n",
    "    mesh_pqsm = pv.read(folder_pqsm)\n",
    "    mesh_nqsm = pv.read(folder_nqsm)\n",
    "    \n",
    "    qsm_bool = True\n",
    "    \n",
    "except:\n",
    "    print(\"No QSM Data available.\")\n",
    "    \n",
    "    qsm_bool = False\n",
    "    \n",
    "if qsm_bool:\n",
    "    # plot mesh #\n",
    "    p = pv.Plotter()\n",
    "    p.set_background('white')\n",
    "    p.add_mesh(mesh_qsm, cmap='PuOr', clim=[-0.05, 0.05],below_color=\"#ffffff\",show_scalar_bar=False)\n",
    "    p.camera_position = p4_camera_position\n",
    "    p.show()\n",
    "    \n",
    "    # apply binary BA3b mask to maps #\n",
    "    tmp1=mesh_qsm\n",
    "    qsm=tmp1['EmbedVertex']*tmp['EmbedVertex']\n",
    "    mesh_qsm['EmbedVertex']=qsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_idx_all = []\n",
    "embed_vert_qsm_all = []\n",
    "embed_vert_pqsm_all = []\n",
    "embed_vert_nqsm_all = []\n",
    "\n",
    "embed_vert_h_all = []\n",
    "embed_vert_f_all = []\n",
    "embed_vert_d5_all = []\n",
    "\n",
    "mesh_points_str = []\n",
    "mesh_points_str_repl = []\n",
    "\n",
    "mesh_points_str = list(map(str,mesh_qT1_im.points))\n",
    "mesh_points_str_repl = [sub.replace(\" \", \"\") for sub in mesh_points_str]\n",
    "\n",
    "for k in range(len(border_loc_mesh)):\n",
    "    mesh_idx = []\n",
    "    emb_vert_qsm = []\n",
    "    emb_vert_pqsm = []\n",
    "    emb_vert_nqsm = []\n",
    "    emb_vert_h = []\n",
    "    emb_vert_f = []\n",
    "    emb_vert_d5 = []\n",
    "    \n",
    "    for i in range(0,len(border_loc_mesh[k])):\n",
    "        target_location = str(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "        target_location1 = target_location.replace(\" \", \"\")\n",
    "        print(target_location1)\n",
    "\n",
    "        try:\n",
    "            print(mesh_points_str_repl.index(target_location1))\n",
    "            mesh_idx.append(mesh_points_str_repl.index(target_location1))\n",
    "        except:\n",
    "            print(\"Value not in list.\")\n",
    "            \n",
    "        try:\n",
    "            emb_vert_qsm.append(mesh_qsm['EmbedVertex'][mesh_points_str_repl.index(target_location1)])\n",
    "            emb_vert_pqsm.append(mesh_pqsm['EmbedVertex'][mesh_points_str_repl.index(target_location1)])\n",
    "            emb_vert_nqsm.append(mesh_nqsm['EmbedVertex'][mesh_points_str_repl.index(target_location1)])\n",
    "        except:\n",
    "            print(\"No QSM Data.\")\n",
    "        \n",
    "        try:\n",
    "             emb_vert_ecm.append(mesh_ecm['EmbedVertex'][mesh_points_str_repl.index(target_location1)])\n",
    "        except:\n",
    "            print(\"No ECM Data.\")\n",
    "            \n",
    "        try:\n",
    "            emb_vert_f.append(mesh_f['EmbedVertex'][mesh_points_str_repl.index(target_location1)])\n",
    "        except:\n",
    "            print(\"No f Map.\")\n",
    "            \n",
    "        try:\n",
    "            emb_vert_h.append(mesh_h['EmbedVertex'][mesh_points_str_repl.index(target_location1)])\n",
    "        except:\n",
    "            print(\"No h Map.\")\n",
    "            \n",
    "    \n",
    "    mesh_idx_all.append(mesh_idx)\n",
    "    embed_vert_qsm_all.append(emb_vert_qsm)\n",
    "    embed_vert_pqsm_all.append(emb_vert_pqsm)\n",
    "    embed_vert_nqsm_all.append(emb_vert_nqsm)\n",
    "    embed_vert_f_all.append(emb_vert_f)\n",
    "    embed_vert_h_all.append(emb_vert_h)\n",
    "    \n",
    "print(mesh_idx_all)\n",
    "print(embed_vert_qsm_all)\n",
    "print(embed_vert_pqsm_all)\n",
    "print(embed_vert_nqsm_all)\n",
    "print(embed_vert_f_all)\n",
    "print(embed_vert_h_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borderidx = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "borderqsm = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "borderaqsm = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "borderpqsm = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "bordernqsm = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "borderf = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "borderh = np.empty((5,5,)) * np.nan # 5 paths x 5 borders\n",
    "\n",
    "for j in range(0,len(mesh_idx_all)):\n",
    "    if len(mesh_idx_all[j]) > 0:\n",
    "        for k in range(0,len(mesh_idx_all[j])):\n",
    "            borderidx[j][k] = mesh_idx_all[j][k]      \n",
    "borderidx = np.array(borderidx).transpose()\n",
    "\n",
    "for j in range(0,len(embed_vert_qsm_all)):\n",
    "    if len(embed_vert_qsm_all[j]) > 0:\n",
    "        for k in range(0,len(embed_vert_qsm_all[j])):\n",
    "            if embed_vert_qsm_all[j][k] == 0:\n",
    "                borderqsm[j][k] = np.nan\n",
    "                borderaqsm[j][k] = np.nan\n",
    "                borderpqsm[j][k] = np.nan\n",
    "                bordernqsm[j][k] = np.nan\n",
    "            else:\n",
    "                borderqsm[j][k] = embed_vert_qsm_all[j][k]\n",
    "                borderaqsm[j][k] = abs(embed_vert_qsm_all[j][k])\n",
    "                borderpqsm[j][k] = embed_vert_pqsm_all[j][k]\n",
    "                bordernqsm[j][k] = embed_vert_nqsm_all[j][k]\n",
    "\n",
    "borderqsm = np.array(borderqsm).transpose()\n",
    "borderaqsm = np.array(borderaqsm).transpose()\n",
    "borderpqsm = np.array(borderpqsm).transpose()\n",
    "bordernqsm = np.array(bordernqsm).transpose()\n",
    "\n",
    "for j in range(0,len(embed_vert_h_all)):\n",
    "    if len(embed_vert_h_all[j]) > 0:\n",
    "        #print(\"test\")\n",
    "        for k in range(0,len(embed_vert_h_all[j])):\n",
    "            if embed_vert_h_all[j][k] == 0:\n",
    "                borderh[j][k] = np.nan\n",
    "            else:\n",
    "                borderh[j][k] = embed_vert_h_all[j][k]\n",
    "borderh = np.array(borderh).transpose()\n",
    "\n",
    "for j in range(0,len(embed_vert_f_all)):\n",
    "    if len(embed_vert_f_all[j]) > 0:\n",
    "        for k in range(0,len(embed_vert_f_all[j])):\n",
    "            if embed_vert_f_all[j][k] == 0:\n",
    "                borderf[j][k] = np.nan\n",
    "            else:\n",
    "                borderf[j][k] = embed_vert_f_all[j][k]\n",
    "borderf = np.array(borderf).transpose()\n",
    "\n",
    "print(borderidx)\n",
    "print(borderqsm)\n",
    "    \n",
    "np.savetxt(outdir+ind+\"_border_middle_qsm.csv\", borderqsm, delimiter=\" \")\n",
    "np.savetxt(outdir+ind+\"_border_middle_aqsm.csv\", borderaqsm, delimiter=\" \")\n",
    "np.savetxt(outdir+ind+\"_border_middle_pqsm.csv\", borderpqsm, delimiter=\" \")\n",
    "np.savetxt(outdir+ind+\"_border_middle_nqsm.csv\", bordernqsm, delimiter=\" \")\n",
    "np.savetxt(outdir+ind+\"_border_orig_idx.csv\", borderidx, delimiter=\" \")\n",
    "\n",
    "np.savetxt(outdir+ind+\"_border_middle_f.csv\", borderf, delimiter=\" \")\n",
    "np.savetxt(outdir+ind+\"_border_middle_f.csv\", borderh, delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(header)\n",
    "print(border_params)\n",
    "\n",
    "border_params_allsubj = np.genfromtxt(outdir_all+\"allsubj_border_params_middle_multi_y_paths.csv\",delimiter=\",\")\n",
    "print(border_params_allsubj)\n",
    "print(border_params_allsubj[ind_i])\n",
    "\n",
    "\n",
    "mean_sqsm = np.nanmean(borderqsm,axis=0)\n",
    "print('sqsm')\n",
    "print(mean_sqsm)\n",
    "\n",
    "mean_aqsm = np.nanmean(abs(borderqsm),axis=0)\n",
    "print('aqsm')\n",
    "print(mean_aqsm)\n",
    "\n",
    "mean_pqsm = np.nanmean(borderpqsm,axis=0)\n",
    "print('pqsm')\n",
    "print(mean_pqsm)\n",
    "\n",
    "mean_nqsm = np.nanmean(bordernqsm,axis=0)\n",
    "print('nqsm')\n",
    "print(mean_nqsm)\n",
    "\n",
    "mean_f = np.nanmean(borderf,axis=0)\n",
    "print(mean_f)\n",
    "\n",
    "mean_h = np.nanmean(borderh,axis=0)\n",
    "print(mean_h)\n",
    "\n",
    "for i in range(0,len(mean_sqsm)):\n",
    "    \n",
    "    colsqsm = np.where(header == 'borderqsm'+str(i+1))[1]\n",
    "    print(colsqsm)\n",
    "    colaqsm = np.where(header == 'borderaqsm'+str(i+1))[1]\n",
    "    colpqsm = np.where(header == 'borderpqsm'+str(i+1))[1]\n",
    "    colnqsm = np.where(header == 'bordernqsm'+str(i+1))[1]\n",
    "    \n",
    "    border_params_allsubj[ind_i][colsqsm] = mean_sqsm[i]\n",
    "    border_params_allsubj[ind_i][colaqsm] = mean_aqsm[i]\n",
    "    border_params_allsubj[ind_i][colpqsm] = mean_pqsm[i]\n",
    "    border_params_allsubj[ind_i][colnqsm] = mean_nqsm[i]\n",
    "    \n",
    "for i in range(0,len(mean_f)):\n",
    "    \n",
    "    colf = np.where(header == 'borderspmTf'+str(i+1))[1]\n",
    "    print(colf)\n",
    "    \n",
    "    border_params_allsubj[ind_i][colf] = mean_f[i]\n",
    "    \n",
    "for i in range(0,len(mean_h)):\n",
    "    \n",
    "    colh = np.where(header == 'borderspmTh'+str(i+1))[1]\n",
    "    print(colh)\n",
    "    \n",
    "    border_params_allsubj[ind_i][colh] = mean_h[i]\n",
    "    \n",
    "print(border_params_allsubj[ind_i])\n",
    "\n",
    "np.savetxt(outdir_all+\"allsubj_border_params_middle_multi_y_paths.csv\", border_params_allsubj, delimiter=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qsm_bool = True\n",
    "\n",
    "mesh_qsm.translate((-0.015,0,0))\n",
    "    \n",
    "if qsm_bool == True:\n",
    "    \n",
    "    vtx_qsm = mesh_qsm['EmbedVertex']\n",
    "    \n",
    "    # plot ecm together with borders\n",
    "    p0 = pv.Plotter()\n",
    "    p0.set_background('white')\n",
    "    p0.add_mesh(mesh_qsm, cmap='PuOr', clim=[-0.05, 0.05],below_color=\"#ffffff\",show_scalar_bar=True)\n",
    "\n",
    "    for k in range(len(border_loc_mesh)):\n",
    "        for i in range(0,len(border_loc_mesh[k])):\n",
    "            p0.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=9, color = crgb[k])\n",
    "            #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "\n",
    "    p0.camera_position = p4_camera_position\n",
    "    p0.camera.zoom(2.0)\n",
    "    #p4.enable_anti_aliasing('msaa')\n",
    "    #p4.camera.view_frustum(1.0)\n",
    "    #p4.camera.view_angle = 20\n",
    "    p0.show()\n",
    "\n",
    "    #save surface plot\n",
    "    p0 = pv.Plotter(off_screen=True)\n",
    "    p0.set_background('white')\n",
    "    p0.add_mesh(mesh_qsm, cmap='PuOr', clim=[-0.05, 0.05],below_color=\"#ffffff\", show_scalar_bar=True)\n",
    "\n",
    "    for k in range(len(border_loc_mesh)):\n",
    "        for i in range(0,len(border_loc_mesh[k])):\n",
    "            p0.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=10, color = crgb[k])\n",
    "            #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "\n",
    "    p0.camera_position = p4_camera_position\n",
    "    p0.camera.zoom(2.0)\n",
    "    p0.screenshot(outdir+ind+'_qsm_final_borders_smooth_zoomed.png', window_size=(500,950))\n",
    "\n",
    "    #save surface plot\n",
    "    p0 = pv.Plotter(off_screen=True)\n",
    "    p0.set_background('white')\n",
    "    p0.add_mesh(mesh_qsm, cmap='PuOr', clim=[-0.04, 0.04],below_color=\"#ffffff\", show_scalar_bar=True)\n",
    "\n",
    "    for k in range(len(border_loc_mesh)):\n",
    "        for i in range(0,len(border_loc_mesh[k])):\n",
    "            p0.add_points(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:], point_size=10, color = \"white\")\n",
    "            #print(merged_path[border_loc_mesh[k][i][0]].points[border_loc_mesh[k][i][1],:])\n",
    "\n",
    "    p0.camera_position = p4_camera_position\n",
    "    p0.camera.zoom(2.0)\n",
    "    p0.screenshot(outdir+ind+'_qsm_final_borders_smooth_zoomed_white.png', window_size=(500,950))\n",
    "    \n",
    "else:\n",
    "    print(\"No qsm Data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
